{
  "meta": {
    "title": "Beyond the Hype: Real Data on enterprise AI implementation costs reality 2025",
    "description": "Comprehensive analysis of enterprise AI implementation costs reality 2025 based on 16 data points from 12 sources. Includes real implementation costs, failure rates, and success patterns.",
    "keywords": [
      "pricing",
      "percent",
      "business",
      "companies",
      "models",
      "organizations",
      "enterprise",
      "leaders",
      "employees",
      "considerations:",
      "implementation",
      "solutions",
      "across",
      "report",
      "development",
      "integration",
      "performance",
      "custom",
      "adoption",
      "significant"
    ],
    "audience": "general",
    "readingTime": 130,
    "publishDate": "2025-09-22T04:25:15.631Z",
    "sources": [
      {
        "url": "https://medium.com/@dejanmarkovic_53716/custom-ai-solutions-cost-guide-2025-pricing-insights-revealed-cf19442261ec",
        "title": "Custom AI Solutions Cost Guide 2025: Pricing Insights ...",
        "type": "article",
        "date": "2025-09-22T04:25:05.036Z",
        "score": 6,
        "metadata": {
          "snippet": "2025 Price Ranges: Custom AI solution costs vary from $50,000 for basic implementations to $500,000+ for enterprise-level systems, with factors ...",
          "domain": "medium.com",
          "breadcrumb": "4 likes  ·  5 months ago",
          "is_featured": false,
          "content": "Custom AI Solutions Cost Guide 2025: Pricing Insights Revealed Dejan Markovic, co-founder https://hypestudio.org/ 18 min read · Mar 31, 2025 -- 1 Listen Share What does it really cost to implement a custom AI solution in 2025? For enterprise leaders navigating digital transformation, understanding the pricing landscape is critical to planning smarter investments and achieving sustainable ROI. From initial development expenses to long-term scalability, the stakes — and the costs — are high. This guide provides a comprehensive breakdown of custom AI solution costs in 2025, offering actionable insights into factors like talent expenses, integration challenges, and industry-specific variations. Whether you’re budgeting for a cutting-edge system or evaluating ROI potential, this resource will equip you with the clarity needed to make data-driven decisions. Key Takeaways 2025 Price Ranges: Custom AI solution costs vary from $50,000 for basic implementations to $500,000+ for enterprise-level systems, with factors like complexity and scale driving pricing. ROI Considerations: While the initial investment is substantial, enterprises can expect a 30–40% cost reduction in operations and a 25% increase in productivity within 18–24 months of implementation. Talent Costs: AI development team expenses represent 40–60% of total project costs, with senior AI engineers commanding $150,000-$200,000 annually in 2025. Implementation Timeline: Enterprise-level custom AI solutions typically require 6–12 months for full deployment, impacting total cost through extended development and integration periods. Scalability Investment: Organizations should allocate 15–20% of initial project costs for scalability features, ensuring long-term value and system adaptability. Industry-Specific Variations: Highly regulated industries like healthcare and finance face 20–30% higher implementation costs due to compliance requirements and specialized features. Maintenance Costs: Annual maintenance and updates typically amount to 15–25% of initial development costs, ensuring optimal performance and security. Integration Expenses: Legacy system integration can add 25–35% to base costs, varying significantly based on existing infrastructure complexity. Cost-Saving Opportunities: Phased implementation approaches can reduce initial costs by 20–30% while allowing for strategic scaling based on performance metrics. The landscape of custom AI solutions continues to evolve rapidly as we approach 2025, with enterprises increasingly recognizing the competitive advantages these technologies offer. This comprehensive guide examines the cost structures, implementation considerations, and ROI projections that decision-makers need to understand when investing in custom AI solutions. Understanding the Cost Structure of Custom AI Solutions in 2025 Press enter or click to view image in full size The Custom AI Solutions Cost Guide 2025 begins by recognizing that AI pricing is multifaceted and depends on several key factors. The primary cost drivers for enterprise AI implementations include data preparation, algorithm development, infrastructure requirements, integration complexity, and ongoing maintenance. Data acquisition and preparation typically account for 15–25% of total project costs, as high-quality, properly structured data forms the foundation of any effective AI system. Algorithm development and customization represent another 20–30% of expenses, varying based on the complexity of the business problem being addressed. Infrastructure costs, including cloud computing resources, storage, and processing power, contribute 10–20% to the overall investment. These expenses scale with the volume of data processed and the computational intensity of the AI models deployed. Integration with existing systems adds 15–25% to project costs, with legacy system compatibility often presenting significant challenges. Finally, ongoing maintenance, updates, and model retraining account for 20–30% of the total cost of ownership over a typical three-year period. A mid-sized financial services company recently invested $175,000 in a custom AI solution for fraud detection, with 22% allocated to data preparation, 28% to algorithm development, 15% to infrastructure, 18% to integration, and 17% to first-year maintenance costs. Key Price Ranges for Custom AI Implementations In 2025, AI pricing spans a wide spectrum based on implementation scope and complexity. Basic AI implementations with limited functionality and minimal integration requirements typically range from $50,000 to $150,000. These solutions address specific, well-defined business problems with standardized approaches. Mid-range AI implementations, suitable for departmental or division-wide deployment, generally cost between $150,000 and $500,000. These solutions incorporate more sophisticated algorithms, handle larger data volumes, and offer deeper integration with existing business systems. Enterprise-level AI implementations, designed for organization-wide deployment with complex integrations and advanced capabilities, range from $500,000 to $2 million or more. These comprehensive solutions often involve multiple AI technologies working to address complex business challenges. Several factors significantly impact these price ranges. Solution complexity adds 25–40% to base costs when advanced algorithms or novel approaches are required. Data volume and quality issues can increase costs by 15–30%, while scalability requirements add 10–25% to ensure future growth accommodation. Industry-specific requirements, such as compliance with healthcare regulations or financial services standards, can add 15–35% to implementation costs due to additional security, governance, and documentation requirements. Pricing Models for AI Solutions The artificial intelligence cost structure is evolving beyond traditional project-based pricing. In 2025, enterprises can choose from several pricing models: Fixed-price projects with clearly defined scope and deliverables Time and materials pricing for projects with evolving requirements Subscription-based models with ongoing access to AI capabilities Outcome-based pricing tied to specific business results Hybrid models combining upfront implementation costs with performance-based components Each model offers different risk and reward profiles, with 63% of enterprises now preferring hybrid approaches that align vendor incentives with business outcomes while maintaining predictable base costs. The Financial Implications of ROI in AI Investments Understanding the return on investment for enterprise AI investment requires examining both direct cost reductions and productivity enhancements. According to recent industry analyses, well-implemented AI solutions deliver average cost reductions of 15–30% in targeted business processes through automation, error reduction, and resource optimization. Productivity gains typically range from 20–35% in affected departments, stemming from faster decision-making, reduced manual work, and improved accuracy. Revenue enhancement opportunities add another dimension, with AI-driven customer insights and personalization generating 10–25% increases in conversion rates and customer lifetime value. The timeline for realizing these returns varies by implementation type. Focused, process-specific AI implementations often achieve positive ROI within 6–12 months. Department-wide solutions typically reach breakeven at 12–18 months, while enterprise-scale implementations generally require 18–36 months to deliver full financial returns. A global manufacturing company implemented a $650,000 predictive maintenance AI system that reduced unplanned downtime by 37%, decreased maintenance costs by 28%, and extended equipment lifespan by 22%. The solution achieved positive ROI in 14 months and delivered a 3.2x return over three years. For enterprises embracing AI and automation , the most significant ROI accelerators include clear business case definitions, phased implementation approaches, and active change management programs that ensure rapid adoption and utilization. Breaking Down AI Development and Talent Acquisition Costs The human element remains a critical cost factor in the breakdown of AI development costs. In 2025, specialized AI talent commands premium compensation, with senior AI engineers earning $150,000 to $250,000 annually in North America, and experienced data scientists commanding $130,000 to $200,000. AI architects who design comprehensive solutions earn $180,000 to $300,000, while AI project managers with technical expertise receive $140,000 to $220,000. These salary ranges vary by geographic location, with Silicon Valley and New York commanding 15–25% premiums over other North American markets. For enterprises building internal AI capabilities, talent acquisition costs extend beyond salaries to include recruitment expenses (typically $30,000-$50,000 per senior position), onboarding costs, and retention programs. Many organizations find that total compensation packages, including benefits and equity, add 25–40% to base salary costs. The talent shortage continues to impact project timelines and costs, with 68% of enterprises reporting difficulties filling specialized AI positions. This scarcity drives many organizations toward hybrid staffing models that combine internal teams with external partners. Internal team development: High control but significant investment in recruitment and retention External partners: Faster access to expertise but potentially higher hourly rates Hybrid models: Balanced approach with knowledge transfer components Organizations implementing custom AI vs. pre-built solutions must factor these talent considerations into their total cost of ownership calculations, as ongoing development and maintenance require sustained access to specialized skills. Timeline Considerations for Implementing Enterprise AI Solutions Press enter or click to view image in full size The implementation timeline for custom AI solutions significantly impacts both costs and realized benefits. In 2025, typical enterprise AI implementation timelines range from 3–6 months for focused, single-process solutions to 12–24 months for comprehensive, organization-wide platforms. These timelines break down into several distinct phases: Discovery and planning: 1–2 months Data preparation and infrastructure setup: 1–3 months Algorithm development and training: 2–6 months Integration and testing: 1–4 months Deployment and initial optimization: 1–3 months Change management and user adoption: Ongoing throughout the project Extended timelines directly impact costs through increased resource allocation, delayed benefit realization, and potential scope expansion. Each month of implementation typically adds 5–8% to project costs while delaying ROI realization. Accelerated implementation approaches can reduce timelines by 20–30% through parallel workstreams, agile methodologies, and focused scope management. However, compressed schedules often require 10–15% higher resource allocation during peak periods. A healthcare provider implementing a patient journey optimization AI reduced their timeline from 18 to 12 months by adopting a modular approach, deploying capabilities incrementally rather than waiting for the complete solution. This approach accelerated benefit realization by $1.2 million while maintaining quality standards. For optimal results, enterprises should balance implementation speed with quality considerations, recognizing that rushed deployments often lead to adoption challenges and performance issues that ultimately extend the time to positive ROI. Allocating for Scalability and Industry-Specific Requirements Investing in scalable custom AI solutions represents a critical decision point that significantly impacts long-term costs. While scalable architectures typically add 15–25% to initial implementation costs, they reduce future expansion expenses by 40–60% compared to solutions that require substantial reworking to accommodate growth. Key scalability considerations include: Data volume growth projections (typically 40–60% annually for AI systems) User base expansion across departments and geographies Processing capacity for peak demand periods Integration with additional systems and data sources Algorithm complexity evolution as business needs mature Industry-specific requirements add another layer of cost variability. Healthcare AI implementations typically cost 25–40% more than comparable solutions in less regulated industries due to HIPAA compliance, data security, and clinical validation requirements. Financial services implementations command 20–35% premiums for regulatory compliance, fraud prevention capabilities, and real-time processing requirements. Manufacturing AI solutions add 15–30% for industrial system integrations, sensor networks, and hardened deployment environments. Retail and e-commerce implementations typically align with baseline costs but may require additional investment in customer data integration and real-time recommendation capabilities. A pharmaceutical company initially saved $200,000 by implementing a non-scalable AI solution for clinical trial optimization but later spent $1.2 million rebuilding the system when data volumes increased tenfold. This experience highlights the false economy of under-investing in scalability for mission-critical AI applications. Organizations should choose AI automation agencies with specific experience in their industry to ensure solutions address unique requirements without unnecessary customization costs. Integration Challenges and Costs with Existing Systems Integration represents one of the most variable and potentially costly aspects of enterprise AI investment. The complexity of connecting AI systems with existing infrastructure depends largely on the age, architecture, and documentation quality of legacy systems. Modern, API-enabled systems with well-documented interfaces typically require $50,000-$150,000 in integration work for mid-sized implementations. Legacy systems with limited connectivity options can increase these costs to $150,000-$500,000 or more, often requiring custom middleware development and extensive testing. The primary integration cost drivers include: Data extraction and transformation complexity Real-time vs. batch processing requirements Security and compliance considerations Performance optimization needs Operational monitoring and management integration Organizations with highly fragmented IT landscapes typically spend 25–40% of their total AI implementation budget on integration activities. Those with modernized, service-oriented architectures often reduce this proportion to 10–20%. Integration approaches vary in cost and effectiveness. Point-to-point integrations offer the fastest implementation but create maintenance challenges as systems evolve. Enterprise service bus (ESB) approaches cost 30–50% more initially but reduce long-term maintenance expenses by 40–60%. API-first strategies balance immediate needs with future flexibility. A financial services firm reduced integration costs by 35% by implementing a data virtualization layer before their AI project, creating standardized access patterns that simplified connections to multiple legacy systems. For organizations with significant legacy infrastructure, conducting an integration readiness assessment before finalizing AI implementation budgets can prevent costly surprises and implementation delays. Maintenance and Continuous Improvement Expenses The ongoing costs of maintaining custom AI solutions represent a significant portion of total ownership expenses, typically ranging from 15–30% of the initial implementation cost annually. These expenses ensure systems remain accurate, secure, and aligned with evolving business needs. Core maintenance activities include: Model retraining and performance monitoring (5–10% of annual costs) Data pipeline maintenance and quality assurance (4–8%) Infrastructure updates and scaling (3–7%) Security patches and vulnerability management (2–5%) User support and training for new capabilities (3–6%) Beyond basic maintenance, continuous improvement investments add another 10–20% annually but deliver substantial returns through enhanced capabilities and performance. These improvements typically focus on algorithm refinement, feature expansion, and integration with new data sources. The maintenance cost structure varies by deployment model. Cloud-based AI solutions offer more predictable maintenance costs but may incur higher operational expenses as usage scales. On-premises deployments provide greater cost control at scale but require more significant internal support resources. A retail organization implementing a customer behavior prediction AI initially budgeted only 10% of implementation costs for annual maintenance, resulting in declining accuracy and business impact after 14 months. After increasing their maintenance investment to 22%, they restored performance and achieved a 28% improvement in prediction accuracy. Organizations should establish clear performance metrics and monitoring processes to ensure maintenance investments deliver appropriate returns. Predictive maintenance approaches that address potential issues before they impact business operations typically reduce total maintenance costs by 15–25% compared to reactive approaches. Strategies for Cost Optimization in AI Project Implementation Implementing custom AI solutions cost-effectively requires strategic approaches that balance immediate budget constraints with long-term value creation. A phased implementation strategy typically reduces initial costs by 20–30% while accelerating time to the first value. Effective phasing approaches include: Starting with high-value, well-defined use cases Implementing core capabilities before advanced features Limiting initial integrations to essential systems Focusing on specific business units before enterprise-wide deployment Building data foundations incrementally as needs evolve Cloud-based development and deployment environments reduce upfront infrastructure costs by 40–60% compared to on-premises approaches while providing greater flexibility to scale resources as needed. Many organizations adopt hybrid approaches, using cloud resources for development and testing while maintaining production environments on-premises for sensitive applications. Open-source components can reduce development costs by 15–30% for standard AI capabilities, though they typically require additional integration and security hardening. Commercial accelerators and pre-built components offer similar savings with reduced integration complexity. A transportation company reduced its AI implementation costs by 32% by adopting a modular architecture that allowed it to leverage existing components across multiple use cases. This approach also accelerated development by 40% for subsequent projects. For organizations new to AI implementation, starting with a proof of concept (POC) that addresses a specific business challenge can validate approaches before committing to larger investments. Effective POCs typically cost $50,000-$150,000 and deliver valuable insights that improve full implementation success rates. AI automation agencies can help identify cost optimization opportunities without compromising solution effectiveness, particularly for organizations with limited internal AI expertise. Final Considerations for Enterprise AI Decision Makers Press enter or click to view image in full size As enterprise leaders evaluate how much custom AI development costs for enterprises in 2025, several critical factors should inform their decision-making process. First, alignment between AI investments and strategic business objectives provides the foundation for meaningful ROI. Solutions addressing core business challenges typically deliver 30–50% higher returns than those focused on peripheral processes. Data readiness represents another crucial consideration, as organizations with mature data governance and management practices typically reduce implementation costs by 20–35% and accelerate time-to-value by 40–60%. Conducting a data readiness assessment before committing to AI investments can identify preparation needs and associated costs. Organizational change management capabilities significantly impact adoption rates and realized benefits. Companies that invest 8–12% of project budgets in change management activities achieve adoption rates 60–80% higher than those allocating less than 5% to these efforts. The build vs. buy decision continues to evolve as the AI solution marketplace matures. While custom development offers maximum alignment with specific business needs, it typically costs 2–3 times more than adapting commercial solutions. Many organizations now pursue hybrid approaches, customizing commercial platforms for unique requirements rather than building entirely from scratch. Finally, governance frameworks that address ethical considerations, bias monitoring, and regulatory compliance have become essential components of successful AI implementations. These frameworks typically add 5–10% to project costs but mitigate significant risks that could otherwise undermine business value. A global insurance company created a comprehensive AI investment framework that evaluated potential projects based on strategic alignment, data readiness, organizational impact, and technical feasibility. This approach increased their AI project success rate from 35% to 78% while reducing average implementation costs by 22%. By considering these factors affecting AI solution prices for large corporations, decision-makers can develop realistic budgets and implementation plans that maximize the long-term ROI of enterprise-level AI investments. Emerging Pricing Models for AI Solutions in 2025 The AI pricing 2025 landscape is evolving beyond traditional project-based approaches to embrace more flexible and value-aligned models. Consumption-based pricing, which charges based on actual usage metrics like API calls, processing time, or data volume, now represents 35% of enterprise AI implementations, up from 18% in 2023. Outcome-based pricing models, where vendors share risk and reward by tying compensation to achieved business results, have grown to 22% of enterprise agreements. These arrangements typically include base fees covering 60–70% of total costs, with the remainder linked to specific performance indicators. Subscription models with tiered capability access continue to gain popularity for ongoing AI services, offering predictable costs and regular updates. These models now account for 28% of enterprise AI engagements, particularly for solutions requiring continuous evolution. Hybrid pricing approaches combining elements of multiple models have become the preference for complex implementations, allowing organizations to balance risk, predictability, and alignment with business outcomes. A retail banking organization negotiated an AI-powered customer service solution with 65% fixed pricing and 35% tied to measurable improvements in resolution rates and customer satisfaction. This arrangement reduced upfront investment by 28% while ensuring vendor commitment to business outcomes. As the market matures, pricing transparency has improved significantly, with benchmarking data now available for most common AI implementation types. This transparency has reduced price variability for standard implementations by 15–25% since 2023. Organizations should evaluate pricing models based on their risk tolerance, budget certainty requirements, and confidence in defined outcomes. Those with well-defined use cases and clear success metrics often benefit most from outcome-based components, while those with evolving requirements may prefer consumption-based approaches. AI Talent Acquisition and Development Strategies AI talent acquisition remains a significant challenge and cost driver for organizations implementing custom solutions. In 2025, enterprises are adopting multi-faceted approaches to address these challenges while managing costs effectively. Internal talent development programs have gained traction, with 58% of large enterprises now offering AI upskilling pathways for existing technical staff. These programs typically cost $15,000-$30,000 per employee but reduce external hiring needs by 30–50% for mid-level positions. University partnerships provide another avenue for talent acquisition, with structured internship and research collaboration programs yielding hiring conversion rates of 45–65% for entry and mid-level positions. These partnerships require $100,000-$250,000 annual investments but create sustainable talent pipelines. Distributed team models leveraging global talent pools can reduce average compensation costs by 25–40% while maintaining quality standards. These approaches require additional investment in collaboration tools and management processes but deliver net savings for most organizations. For specialized roles requiring rare expertise, contract-to-hire arrangements with performance-based conversion incentives have proven effective at reducing risk while securing top talent. These arrangements typically include 10–20% premiums over standard compensation but improve retention rates by 30–50%. A technology company created an AI talent development academy that combined formal training with mentored project work, reducing their external hiring needs by 42% and decreasing time-to-productivity for new AI team members by 35%. Organizations should develop comprehensive talent strategies that balance immediate implementation needs with long-term capability building. Those relying exclusively on external hiring typically spend 30–45% more on talent acquisition and face greater project delays than those with balanced approaches. Understanding generative AI and other emerging technologies requires continuous learning programs that keep teams current with rapidly evolving capabilities and best practices. ROI Measurement Frameworks for AI Investments Press enter or click to view image in full size Quantifying the return on enterprise AI investment requires structured measurement frameworks that capture both direct and indirect benefits. Leading organizations now employ multi-dimensional approaches that track financial returns alongside operational improvements and strategic advantages. Effective ROI frameworks typically include: Direct cost reduction metrics (labor savings, error reduction, resource optimization) Productivity enhancement measures (throughput increases, cycle time reductions) Revenue impact indicators (conversion rate improvements, customer lifetime value changes) Quality and compliance metrics (error rate reductions, audit findings) Strategic capability indicators (time-to-market improvements, innovation metrics) Organizations with mature measurement practices establish baseline performance before implementation and track changes at regular intervals, typically monthly or quarterly. This approach allows for continuous optimization and helps identify areas requiring additional attention. Attribution methodologies have evolved to address the challenge of isolating AI impact from other business changes. Controlled experiments, where possible, provide the most reliable data, while matched sample analyses and time-series comparisons offer alternatives for situations where direct experiments aren’t feasible. A manufacturing company implemented a comprehensive measurement framework for their predictive maintenance AI that tracked direct maintenance cost savings, production uptime improvements, parts inventory reductions, and equipment lifespan extensions. This multi-dimensional approach demonstrated a 3.8x ROI over three years, substantially higher than the 2.2x identified through cost savings alone. For maximum effectiveness, ROI measurement should begin during the planning phase by defining specific, measurable outcomes tied to business priorities. Organizations that establish clear success metrics before implementation are 2.5 times more likely to achieve positive ROI than those that develop metrics after deployment. Regular reporting of AI performance metrics to executive stakeholders maintains visibility and support while creating accountability for realizing projected benefits. Leading organizations review these metrics quarterly and adjust implementation approaches based on observed results. References ddi-dev graphem upsilonit helpcrunch pixelplex Frequently Asked Questions Q: How much does it cost to build a custom AI model? Building a custom AI model is akin to crafting a bespoke suit — tailored to fit your business’s unique needs. The cost can vary widely, depending on factors like project complexity and data requirements. Here are some key considerations: Development Team Costs: Assembling a skilled team of data scientists and machine learning engineers can be expensive, with salaries ranging from $80,000 to $200,000 per year. Data Acquisition and Preparation: High-quality data is essential, but collecting, cleaning, and labeling it can cost tens of thousands of dollars. Infrastructure Costs: Running AI models requires powerful computing resources, such as cloud servers, which can add thousands to the bill. Testing and Maintenance: Ongoing testing and updates are necessary to keep the model performing well, adding more costs over time. For instance, developing a personalized recommendation engine can cost upwards of $200,000 to $500,000, depending on complexity and personalization levels. Q: How much is the AI market worth in 2025? The AI market is a rapidly growing behemoth, with its value projected to soar in the coming years. While exact figures for 2025 are not yet available, the market is expected to experience a significant annual growth rate of 37% between now and 2030. Here are some insights into the AI market’s trajectory: Market Growth Rate: The AI market is projected to grow at an annual rate of 37%, driven by advancements in AI technologies and their adoption across industries. Industry Adoption: AI is being integrated into various sectors, including healthcare, finance, and manufacturing, contributing to its rapid growth. Technological Advancements: Continuous improvements in AI algorithms and computing power are fueling the market’s expansion. Investment Trends: Major companies like Meta and Google are heavily investing in AI research, further propelling the market forward. As AI continues to transform industries, its market value is expected to reach new heights, making it a critical component of future business strategies. Q: How much will AI be worth in 2030? By 2030, the AI market is expected to be a trillion-dollar industry, driven by its widespread adoption and the continuous innovation in AI technologies. Here’s a glimpse into what the future holds: Market Size Projections: The AI market is projected to reach a valuation of over a trillion dollars by 2030, reflecting its growing impact on global industries. Technological Advancements: Advances in AI will continue to drive innovation, leading to more sophisticated applications across sectors. Industry Integration: AI will become integral to operations in healthcare, finance, and manufacturing, among others, contributing to its massive growth. Global Economic Impact: AI is expected to significantly influence global economic trends, transforming how businesses operate and compete. As AI continues to evolve, its potential to reshape industries and economies will only continue to grow. Q: What is the future of AI in 2025? The future of AI in 2025 is bright and transformative. As AI technologies advance, they will play a pivotal role in shaping industries and revolutionizing how businesses operate. Here are some key trends to watch: Increased Adoption: AI will be more widely adopted across industries, enhancing efficiency and decision-making. Advancements in AI Models: Next-generation AI models will offer greater accuracy and personalization, driving innovation in sectors like healthcare and finance. Ethical Considerations: As AI becomes more pervasive, ethical considerations and regulatory frameworks will become increasingly important. Job Market Impact: AI will continue to automate tasks, but it will also create new job opportunities in fields like AI development and deployment. Major companies like Google and Meta are already investing heavily in AI research, setting the stage for a future where AI is integral to business operations. Any Other Questions? That wraps up the most popular questions we get but fire away any others! Contact us to discuss your next development project! FAQ References ddi-dev.com graphem.com upsilonit.com helpcrunch.com pixelplex.io"
        }
      },
      {
        "url": "https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/superagency-in-the-workplace-empowering-people-to-unlock-ais-full-potential-at-work",
        "title": "AI in the workplace: A report for 2025",
        "type": "article",
        "date": "2025-01-28 00:00:00 +00:00",
        "score": 5,
        "metadata": {
          "snippet": "Jan 28, 2025 — McKinsey research sizes the long-term AI opportunity at $4.4 trillion in added productivity growth potential from corporate use cases. 2 “The ...",
          "domain": "www.mckinsey.com",
          "breadcrumb": "https://www.mckinsey.com › capabilities › our-insights",
          "is_featured": false,
          "content": "Superagency in the workplace: Empowering people to unlock AI&rsquo;s full potential January 28, 2025 | Report Hannah Mayer Lareina Yee Michael Chui Roger Roberts Almost all companies invest in AI, but just 1 percent believe they are at maturity. Our research finds the biggest barrier to scaling is not employees&mdash;who are ready&mdash;but leaders, who are not steering fast enough. Superagency in the workplace: Empowering people to unlock AI’s full potential (47 pages) Artificial intelligence has arrived in the workplace and has the potential to be as transformative as the steam engine was to the 19th-century Industrial Revolution. 1 “ Gen AI: A cognitive industrial revolution ,” McKinsey, June 7, 2024. With powerful and capable large language models (LLMs) developed by Anthropic, Cohere, Google, Meta, Mistral, OpenAI, and others, we have entered a new information technology era. McKinsey research sizes the long-term AI opportunity at $4.4 trillion in added productivity growth potential from corporate use cases. 2 “ The economic potential of generative AI: The next productivity frontier ,” McKinsey, June 14, 2023. Therein lies the challenge: the long-term potential of AI is great, but the short-term returns are unclear. Over the next three years, 92 percent of companies plan to increase their AI investments. But while nearly all companies are investing in AI, only 1 percent of leaders call their companies “mature” on the deployment spectrum, meaning that AI is fully integrated into workflows and drives substantial business outcomes. The big question is how business leaders can deploy capital and steer their organizations closer to AI maturity. This research report, prompted by Reid Hoffman’s book Superagency: What Could Possibly Go Right with Our AI Future , 3 Reid Hoffman and Greg Beato, Superagency: What Could Possibly Go Right with Our AI Future , Authors Equity, January 2025. asks a similar question: How can companies harness AI to amplify human agency and unlock new levels of creativity and productivity in the workplace? AI could drive enormous positive and disruptive change. This transformation will take some time, but leaders must not be dissuaded. Instead, they must advance boldly today to avoid becoming uncompetitive tomorrow. The history of major economic and technological shifts shows that such moments can define the rise and fall of companies. Over 40 years ago, the internet was born. Since then, companies including Alphabet, Amazon, Apple, Meta, and Microsoft have attained trillion-dollar market capitalizations. Even more profoundly, the internet changed the anatomy of work and access to information. AI now is like the internet many years ago: The risk for business leaders is not thinking too big, but rather too small. This report explores companies’ technology and business readiness for AI adoption (see sidebar “About the survey”). It concludes that employees are ready for AI. The biggest barrier to success is leadership. Register for McKinsey Live: From Strategy to Performance: How Leaders Can Build an Operating Model That Works Tuesday, September 30 | 10:30 a.m. EDT / 4:30 p.m. CEST In today&rsquo;s rapidly changing environment, shaped by digital disruption, shifting customer expectations, and new ways of working, traditional operating models no longer suffice. Business leaders must rethink how their organizations create value, adapt quickly, and empower talent. Join McKinsey senior partners Alexis Krivkovich and Brooke Weddle as they share a research-backed approach to organizational design, including the &ldquo;nine golden rules&rdquo; for transforming operating models and building capabilities that last. Register About the survey To create our report, we surveyed 3,613 employees (managers and independent contributors) and 238 C-level executives in October and November 2024. Of these, 81 percent came from the United States, and the rest came from five other countries: Australia, India, New Zealand, Singapore, and the United Kingdom. The employees spanned many roles, including business development, finance, marketing, product management, sales, and technology. All the survey findings discussed in the report, aside from two sidebars presenting international nuances, pertain solely to US workplaces. The findings are organized in this way because the responses from US employees and C-suite executives provide statistically significant conclusions about the US workplace. Analyzing global findings separately allows a comparison of differences between US responses and those from other regions. Chapter 1 looks at the rapid advancement of technology over the past two years and its implications for business adoption of AI. Chapter 2 delves into the attitudes and perceptions of employees and leaders. Our research shows that employees are more ready for AI than their leaders imagine. In fact, they are already using AI on a regular basis; are three times more likely than leaders realize to believe that AI will replace 30 percent of their work in the next year; and are eager to gain AI skills. Still, AI optimists are only a slight majority in the workplace; a large minority (41 percent) are more apprehensive and will need additional support. This is where millennials, who are the most familiar with AI and are often in managerial roles, can be strong advocates for change. Chapter 3 looks at the need for speed and safety in AI deployment. While leaders and employees want to move faster, trust and safety are top concerns. About half of employees worry about AI inaccuracy and cybersecurity risks. That said, employees express greater confidence that their own companies, versus other organizations, will get AI right. The onus is on business leaders to prove them right, by making bold and responsible decisions. Chapter 4 examines how companies risk losing ground in the AI race if leaders do not set bold goals. As the hype around AI subsides, companies should put a heightened focus on practical applications that empower employees in their daily jobs. These applications can create competitive moats and generate measurable ROI. Across industries, functions, and geographies, companies that invest strategically can go beyond using AI to drive incremental value and instead create transformative change. Chapter 5 looks at what is required for leaders to set their teams up for success with AI. The challenge of AI in the workplace is not a technology challenge. It is a business challenge that calls upon leaders to align teams, address AI headwinds, and rewire their companies for change. Chapter 1 An innovation as powerful as the steam engine Imagine a world where machines not only perform physical labor but also think, learn, and make autonomous decisions. This world includes humans in the loop, bringing people and machines together in a state of superagency that increases personal productivity and creativity (see sidebar “AI superagency”). This is the transformative potential of AI, a technology with a potential impact poised to surpass even the biggest innovations of the past, from the printing press to the automobile. AI does not just automate tasks but goes further by automating cognitive functions. Unlike any invention before, AI-powered software can adapt, plan, guide—and even make—decisions. That’s why AI can be a catalyst for unprecedented economic growth and societal change in virtually every aspect of life. It will reshape our interaction with technology and with one another. Scientific discoveries and technological innovations are stones in the cathedral of human progress. Reid Hoffman, cofounder of LinkedIn and Inflection AI, partner at Greylock Partners, and author Many breakthrough technologies, including the internet, smartphones, and cloud computing, have transformed the way we live and work. AI stands out from these inventions because it offers more than access to information. It can summarize, code, reason, engage in a dialogue, and make choices. AI can lower skill barriers, helping more people acquire proficiency in more fields, in any language and at any time. AI holds the potential to shift the way people access and use knowledge. The result will be more efficient and effective problem solving, enabling innovation that benefits everyone. AI superagency What impact will AI have on humanity? Reid Hoffman and Greg Beato’s book Superagency: What Could Possibly Go Right with Our AI Future (Authors Equity, January 2025) explores this question. The book highlights how AI could enhance human agency and heighten our potential. It envisions a human-led, future-forward approach to AI. Superagency, a term coined by Hoffman, describes a state where individuals, empowered by AI, supercharge their creativity, productivity, and positive impact. Even those not directly engaging with AI can benefit from its broader effects on knowledge, efficiency, and innovation. AI is the latest in a series of transformative supertools, including the steam engine, internet, and smartphone, that have reshaped our world by amplifying human capabilities. Like its predecessors, AI can democratize access to knowledge and automate tasks, assuming humans can develop and deploy it safely and equitably. Over the past two years, AI has advanced in leaps and bounds, and enterprise-level adoption has accelerated due to lower costs and greater access to capabilities. Many notable AI innovations have emerged (Exhibit 1). For example, we have seen a rapid expansion of context windows, or the short-term memory of LLMs. The larger a context window , the more information an LLM can process at once. To illustrate, Google’s Gemini 1.5 could process one million tokens in February 2024, while its Gemini 1.5 Pro could process two million tokens by June of that same year. 4 The Keyword , “Our next-generation model: Gemini 1.5,” blog entry by Sundar Pichai and Demis Hassabis, Google, February 15, 2024; Google for Developers , “Gemini 1.5 Pro 2M context window, code execution capabilities, and Gemma 2 are available today,” blog entry by Logan Kilpatrick, Shrestha Basu Mallick, and Ronen Kofman, June 27, 2024. Overall, we see five big innovations for business that are driving the next wave of impact: enhanced intelligence and reasoning capabilities, agentic AI, multimodality, improved hardware innovation and computational power, and increased transparency. Image description begins: The text-based exhibit illustrates the evolution of capabilities of several gen AI large language models, or LLMs, from select frontier labs between 2022 and 2025. The is presented as a table comparing two time periods: 2022-2023 and January 2025. For each of five LLMs&mdash;Anthropic's Claude, Google's Gemini, Meta's Llama, Microsoft's Phi, and OpenAI's GPT&mdash;the exhibit shows a list of capabilities for each time period. In 2022-2023, all five platforms lacked multimodal capabilities, functioning primarily with text only. Anthropic's Claude, for example, showed limited contextual understanding and no tool usage. Google's Gemini, similarly, had limited real-time data integration and low personalization. Meta's Llama 1 exhibited fair reasoning but had difficulty with complex conversations and lacked API access. Microsoft's Phi-1 had fair reasoning limited to coding tasks, with focused training on a smaller dataset. OpenAI's GPT-3.5 demonstrated fair reasoning, scoring well on the SAT but poorly on the bar examination, while also displaying limited contextual understanding in complex conversations, though it did offer standard API access for text generation. By January 2025, a significant shift is apparent. Claude 3.5, Gemini 2.0 Flash, Llama 3.3, Phi-4, and OpenAI's model o1 all gained multimodal capabilities, incorporating text, audio, and images. Advanced reasoning capabilities, capable of multistep problem-solving and nuanced analysis, became common across most of the platforms. Enhanced contextual understanding, maintaining coherence during long dialogues, is also highlighted as an improvement. Furthermore, real-time data integration and advanced personalization features were added to some platforms. Finally, several platforms highlight improved or advanced API access, allowing for tools related to model and agent development and multimodal inputs. Source: Company websites and press releases. This image description was completed with the assistance of Writer, a gen AI tool. Image description ends. Intelligence and reasoning are improving AI is becoming far more intelligent. One indicator is the performance of LLMs on standardized tests. OpenAI’s Chat GPT-3.5, introduced in 2022, demonstrated strong performance on high-school-level exams (for example, scoring in the 70th percentile on the SAT math and the 87th percentile on the SAT verbal sections). However, it often struggled with broader reasoning. Today’s models are near the intelligence level of people who hold advanced degrees. GPT-4 can so easily pass the Uniform Bar Examination that it would rank in the top 10 percent of test takers, 5 GPT-4 technical report, OpenAI, March 27, 2023. and it can answer 90 percent of questions correctly on the US Medical Licensing Examination. 6 Dana Brin, Vera Sorin, Akhil Vaid, et al., “Comparing ChatGPT and GPT-4 performance in USMLE soft skill assessments,” Scientific Reports , October 1, 2023. The advent of reasoning capabilities represents the next big leap forward for AI. Reasoning enhances AI’s capacity for complex decision making, allowing models to move beyond basic comprehension to nuanced understanding and the ability to create step-by-step plans to achieve goals. For businesses, this means they can fine-tune reasoning models and integrate them with domain-specific knowledge to deliver actionable insights with greater accuracy. Models such as OpenAI’s o1 or Google’s Gemini 2.0 Flash Thinking Mode are capable of reasoning in their responses, which gives users a human-like thought partner for their interactions, not just an information retrieval and synthesis engine. 7 “Learning to reason with LLMs,” OpenAI, September 12, 2024; “Gemini 2.09 Flash Thinking Mode,” Google, January 21, 2025. AI in Action: An interactive learning journey Explore the Superagency learning experience Agentic AI is acting autonomously I’ve always thought of AI as the most profound technology humanity is working on . . . more profound than fire or electricity or anything that we’ve done in the past. Sundar Pichai, CEO of Alphabet The ability to reason is growing more and more, allowing models to autonomously take actions and complete complex tasks across workflows. This is a profound step forward. As an example, in 2023, an AI bot could support call center representatives by synthesizing and summarizing large volumes of data—including voice messages, text, and technical specifications—to suggest responses to customer queries. In 2025, an AI agent can converse with a customer and plan the actions it will take afterward—for example, processing a payment, checking for fraud, and completing a shipping action. Software companies are embedding agentic AI capabilities into their core products. For example, Salesforce’s Agentforce is a new layer on its existing platform that enables users to easily build and deploy autonomous AI agents to handle complex tasks across workflows, such as simulating product launches and orchestrating marketing campaigns. 8 Sammy Spiegel, “The future of AI agents: Top predictions and trends to watch in 2025,” Salesforce, December 2024. Marc Benioff, Salesforce cofounder, chair, and CEO, describes this as providing a “digital workforce” where humans and automated agents work together to achieve customer outcomes. 9 Marc Benioff, “How the rise of new digital workers will lead to an unlimited age,” Time , November 25, 2024. Multimodality is bringing together text, audio, and video Today’s AI models are evolving toward more advanced and diverse data processing capabilities across text, audio, and video. Over the last two years, we have seen improvements in the quality of each modality. For example, Google’s Gemini Live has improved audio quality and latency and can now deliver a human-like conversation with emotional nuance and expressiveness. 10 Ivan Solovyev and Shrestha Basu Mallick, “Gemini 2.0: Level up your apps with real-time multimodal interactions,” Google, December 23, 2024. Also, demonstrations of Sora by OpenAI show its ability to translate text to video. 11 “OpenAI releases AI video generator Sora but limits how it depicts people,” Associated Press, December 10, 2024. Hardware innovation is enhancing performance Hardware innovation and the resulting increase in compute power continue to enhance AI performance. Specialized chips allow faster, larger, and more versatile models. Enterprises can now adopt AI solutions that require high processing power, enabling real-time applications and opportunities for scalability. For example, an e-commerce company could significantly improve customer service by implementing AI-driven chatbots that leverage advanced graphics processing units (GPUs) and tensor processing units (TPUs). Using distributed cloud computing, the company could ensure optimal performance during peak traffic periods. Integrating edge hardware, the company could deploy models that analyze photos of damaged products to more accurately process insurance claims. Transparency is increasing AI, like most transformative technologies, grows gradually, then arrives suddenly. Reid Hoffman, cofounder of LinkedIn and Inflection AI, partner at Greylock Partners, and author AI is gradually becoming less risky, but it still lacks greater transparency and explainability. Both are critical for improving AI safety and reducing the potential for bias, which are imperative for widescale enterprise deployment. There is still a long way to go, but new models and iterations are rapidly improving. Stanford University’s Center for Research on Foundation Models (CRFM) reports significant advances in model performance. Its Transparency Index, which uses a scale of 1 to 100, shows that Anthropic’s transparency score increased by 15 points to 51 and Amazon’s more than tripled to 41 between October 2023 and May 2024. 12 “The Foundation Model Transparency Index,” Stanford Center for Research on Foundation Models, May 2024. Beyond LLMs, other forms of AI and machine learning (ML) are improving explainability, allowing the outputs of models that support consequential decisions (for example, credit risk assessment) to be traced back to the data that informed them. In this way, critical systems can be tested and monitored on a near-constant basis for bias and other everyday harms that arise from model drift and shifting data inputs, which happens even in systems that were well calibrated before deployment. All of this is crucial for detecting errors and ensuring compliance with regulations and company policies. Companies have improved explainability practices and built necessary checks and balances, but they must be prepared to evolve continuously to keep up with growing model capabilities. Achieving AI superagency in the workplace is not simply about mastering technology. It is every bit as much about supporting people, creating processes, and managing governance. The next chapters explore the nontechnological factors that will help shape the deployment of AI in the workplace. Chapter 2 Employees are ready for AI; now leaders must step up Employees will be the ones to make their organizations AI powerhouses. They are more ready to embrace AI in the workplace than business leaders imagine. They are more familiar with AI tools, they want more support and training, and they are more likely to believe AI will replace at least a third of their work in the near future. Now it’s imperative that leaders step up. They have more permission space than they realize, so it’s on them to be bold and capture the value of AI. Now. People are using [AI] to create amazing things. If we could see what each of us can do 10 or 20 years in the future, it would astonish us today. Sam Altman, cofounder and CEO of OpenAI Beyond the tipping point In our survey, nearly all employees (94 percent) and C-suite leaders (99 percent) report having some level of familiarity with gen AI tools. Nevertheless, business leaders underestimate how extensively their employees are using gen AI. C-suite leaders estimate that only 4 percent of employees use gen AI for at least 30 percent of their daily work, when in fact that percentage is three times greater, as self-reported by employees (Exhibit 2). And while only a total of 20 percent of leaders believe employees will use gen AI for more than 30 percent of their daily tasks within a year, employees are twice as likely (47 percent) to believe they will (see sidebar “Who is using AI at work? Nearly everyone, even skeptical employees”). The good news is that our survey suggests three ways companies can accelerate AI adoption and move toward AI maturity. Image description begins: The exhibit shows the anticipated timeline for US employees' and business leaders&rsquo; use of gen AI for more than 30 percent of their daily work tasks, presented as two stacked bar charts, one for C-suite respondents and one for employees. The segments are broken down into five categories representing different timeframes: Already using, less than a year, 1-5 years, over 5 years, and don't anticipate it. A final category, not sure, is also included. A key finding highlighted in the chart is that employees are three times more likely to be using gen AI today than their leaders expect (4 percent of C-suite respondents estimate that employees are currently using gen AI for more than 30 percent of their daily tasks, while 13 percent of employees self-report they are currently doing so). For the C-suite, 16 percent expect employees to start using gen AI for more than 30 percent of their daily tasks within less than a year, 56 percent anticipate such adoption within 1-5 years, 11 percent expect it in over 5 years, and 10 percent don't anticipate employees will ever use gen AI for 30 percent of their work tasks. 3 percent of C-suite respondents are unsure. 34 percent of employees expect to use gen AI for more than 30 percent of their work tasks in less than a year, 37 percent within 1-5 years, 5 percent in over 5 years, and 7 percent don't anticipate ever using it in this way. 4 percent of employees are unsure. Source: McKinsey US CxO survey, Oct&ndash;Nov 2024; McKinsey US employee survey, Oct&ndash;Nov 2024. This image description was completed with the assistance of Writer, a gen AI tool. Image description ends. Leaders can invest more in their employees Who is using AI at work? Nearly everyone, even skeptical employees Our research looked at people who self-identify as “Zoomers,” “Bloomers,” “Gloomers,” and “Doomers” in their attitudes toward AI—a set of archetypes introduced in Superagency . We find that 39 percent of employees identify as Bloomers, who are AI optimists that want to collaborate with their companies to create responsible solutions. Meanwhile, 37 percent identify as Gloomers, who are more skeptical about AI and want extensive top-down AI regulations; 20 percent identify as Zoomers, who want AI to be quickly deployed with few guardrails; and just 4 percent identify as Doomers, who have a fundamentally negative view of AI (exhibit). Even those with a skeptical take on AI are familiar with it; 94 percent of Gloomers and 71 percent of Doomers say they have some familiarity with gen AI tools. Furthermore, approximately 80 percent of Gloomers and about half of Doomers say they are comfortable using gen AI at work. Image descriptions begins: The exhibit depicts US employee sentiment toward gen AI, categorized into four archetypes: Doomer, Gloomer, Bloomer, and Zoomer. Each archetype's perspective is presented through a series of semicircular sunray charts showing the share of respondents within each group holding specific views. For example, two of the sunrays represent two separate sentiments, &ldquo;has extensive familiarity with gen AI&rdquo; and &ldquo;has at least some familiarity with gen AI.&rdquo; The Doomer archetype shows 16 percent with extensive familiarity and 71 percent with at least some familiarity. The Gloomer archetype demonstrates significantly higher percentages: 42 percent with extensive familiarity and 94 percent with at least some. The Bloomer archetype shows 55 percent with extensive familiarity and 96 percent with at least some, and the Zoomer archetype shows 67 percent with extensive familiarity and 96 percent with at least some. The exhibit further illustrates employees&rsquo; comfort levels with using gen AI results, belief in the net benefits of gen AI within the next five years, and plans to utilize gen AI more in their personal lives. In the Doomer archetype, 47 percent say they are comfortable using gen AI results, 54 percent believe in gen AI&rsquo;s net benefit within the next five years, and 49 percent plan increased personal use of gen AI. The Gloomer archetype shows markedly higher percentages in these three areas: 79 percent, 82 percent, and 77 percent respectively. The Bloomer and Zoomer archetypes present even higher percentages across these three metrics; for instance, 91 percent of Zoomers are comfortable using gen AI results, 87 percent believe in gen AI&rsquo;s net benefit within five years, and 85 percent plan to increase their personal use of gen AI. Finally, the exhibit the includes a separate section depicting the share of respondents within each archetype, indicating the size of each group with a series of donut charts. The Doomer group comprises 4 percent of employees, Gloomers are 37 percent, Bloomers are 39 percent, and Zoomers are 20 percent. Source: McKinsey US employee survey, Oct&ndash;Nov 2024. This image description was completed with the assistance of Writer, a gen AI tool. Image description ends. As noted at the beginning of this chapter, employees anticipate AI will have a dramatic impact on their work. Now they would like their companies to invest in the training that will help them succeed. Nearly half of employees in our survey say they want more formal training and believe it is the best way to boost AI adoption. They also would like access to AI tools in the form of betas or pilots, and they indicate that incentives such as financial rewards and recognition can improve uptake. Yet employees are not getting the training and support they need. More than a fifth report that they have received minimal to no support (Exhibit 3). Outside the United States, employees also want more training (see sidebar “Global perspectives on training”). Image description begins: The first section of the exhibit is a horizontal bar chart showing the percentage of US employees who believe that specific company initiatives would increase their daily use of gen AI tools. Formal gen AI training from their organization scored highest at 48 percent, followed by seamless integration into existing workflows (45 percent), access to gen AI tools (41 percent), and incentives and rewards (40 percent). Lower percentages were observed for usage of gen AI being a requirement for a certification program (30 percent), explicit instructions from managers to use gen AI (30 percent), being involved in the development of the tools (29 percent), and OKRs/KPIs tied to gen AI usage (22 percent). The second section is a stacked pair of segmented bar charts illustrating the perceived level of support for gen AI capability building at their organizations, comparing current vs in three years. This chart shows the distribution of responses across four levels of support: not needed, none/minimal, moderate to significant, and fully supported. Currently, 6 percent of employees report that support for gen AI in their organizations is not needed, 22 percent report they receive none/minimal support, 44 percent report moderate to significant support, and 29 percent report they are fully supported. Looking ahead to three years in the future, these percentages are projected to shift considerably: gen AI support not needed drops to 4 percent, none/minimal support for gen AI usage decreases to 10 percent, moderate to significant support for gen AI usage increases to 56 percent, and fully supported increases to 31 percent. Source: McKinsey US employee survey, Oct&ndash;Nov 2024. This image description was completed with the assistance of Writer, a gen AI tool. Image description ends. Sidebar Global perspectives on training To get a clearer picture of global AI adoption trends, we looked at trends across five countries: Australia, India, New Zealand, Singapore, and the United Kingdom. Broadly speaking, these employees and C-suite leaders—the “international” group in this report—have similar views of AI as their US peers. In some key areas, however, including the topic of training, their experiences differ. Many international employees are concerned about insufficient training, even though they report receiving far more support than US employees. Some 84 percent of international employees say they receive significant or full organizational support to learn AI skills, versus just over half of US employees. International employees also have more opportunities to participate in developing gen AI tools at work than their US counterparts, with differences of at least ten percentage points in activities such as providing feedback, beta testing, and requesting specific features (exhibit). C-suite leaders can help millennials lead the way Many millennials aged 35 to 44 are managers and team leaders in their companies. In our survey, they self-report having the most experience and enthusiasm about AI, making them natural champions of transformational change. Millennials are the most active generation of AI users. Some 62 percent of 35- to 44-year-old employees report high levels of expertise with AI, compared with 50 percent of 18- to 24-year-old Gen Zers and 22 percent of baby boomers over 65 (Exhibit 4). By tapping into that enthusiasm and expertise, leaders can help millennials play a crucial role in AI adoption. Image description begins: The exhibit is a grid of proportional area charts displaying US employee sentiment toward gen AI by age group. Each row represents a different sentiment, from top to bottom: has extensive familiarity with gen AI, is comfortable using gen AI at work, provides feedback on gen AI tools, and wants to participate in the design of gen AI tools. The columns represent age groups: 18-24, 25-34, 35-44, 45-54, 55-64, and 65+. The data is presented as percentages of respondents who agreed with each sentiment within each age group. The chart reveals that the 35-44 age group exhibits the most positive sentiment across most categories. For example, 90 percent of this group reports being comfortable using gen AI at work, the highest percentage among all age groups for this metric. This group also shows the highest percentage (62 percent) reporting extensive familiarity with gen AI. In contrast, the 55-64 and 65+ age groups consistently show lower percentages across all four metrics, with only 26 percent and 22 percent of employees in these age groups reporting extensive familiarity with gen AI respectively. The 18-24, 25-34, and 45-54 age groups show intermediate levels of positive sentiment, generally lower than the 35-44 group but higher than the 55-64 and 65+ age groups. Source: McKinsey US employee survey, Oct&ndash;Nov 2024. This image description was completed with the assistance of Writer, a gen AI tool. Image description ends. Since many millennials are managers, they can support their teams to become more adept AI users. This helps push their companies toward AI maturity. Two-thirds of managers say they field questions from their team about how to use AI tools at least once a week, and a similar percentage say they recommend AI tools to their teams to solve problems (Exhibit 5). Image description begins: The exhibit examines US manager respondents and their experiences with gen AI tools. The exhibit is composed of two main sections. The top section of the exhibit examines the frequency of inquiries that managers field from their employees about using new gen AI tools at work. This is depicted as a horizontal bar chart showing percentages of respondents. 5 percent of managers report less than quarterly inquiries; 5 percent report quarterly inquiries; 12 percent report inquiries once a month; 15 percent report once a week; 28 percent report a few times a week; 9 percent report once a day; and 16 percent report multiple times a day. Finally, 10 percent of report not at all. The second section explores the use of gen AI tools to resolve team member challenges. This section uses two donut charts, each showing percentages of respondents. The first donut chart indicates that 68 percent of managers report recommending a gen AI tool to solve a team member's challenge in the past month. The second donut chart shows that 86 percent of managers who recommended a gen AI tool report that the tool was successful in resolving the team member&rsquo;s challenge. Source: McKinsey US employee survey, Oct&ndash;Nov 2024. This image description was completed with the assistance of Writer, a gen AI tool. Image description ends. Since leaders have the permission space, they can be bolder In many transformations, employees are not ready for change, but AI is different. Employee readiness and familiarity are high, which gives business leaders the permission space to act. Leaders can listen to employees describe how they are using AI today and how they envision their work being transformed. They also can provide employees with much-needed training and empower managers to move AI use cases from pilot to scale. It’s critical that leaders meet this moment. It’s the only way to accelerate the probability that their companies will reach AI maturity. But they must move with alacrity, or they will fall behind. Chapter 3 Delivering speed and safety AI technology is advancing at record speed. ChatGPT was released about two years ago; OpenAI reports that usage now exceeds 300 million weekly users 13 Hayden Field, “OpenAI’s active user count soars to 300 million people per week,” CNBC, December 4, 2024. and that over 90 percent of Fortune 500 companies employ its technology. 14 Krystal Hu and Dawn Chmielewski, “OpenAI&#x27;s Altman pitches ChatGPT Enterprise to large firms, including some Microsoft customers,” Reuters, April 12, 2024. The internet did not reach this level of usage until the early 2000s, nearly a decade after its inception. Soon after the first automobiles were on the road, there was the first car crash. But we didn’t ban cars—we adopted speed limits, safety standards, licensing requirements, drunk-driving laws, and other rules of the road. Bill Gates, cofounder of Microsoft The majority of employees describe themselves as AI optimists; Zoomers and Bloomers make up 59 percent of the workplace. Even Gloomers, who are one of the two less-optimistic segments in our analysis, report high levels of gen AI familiarity, with over a quarter saying they plan to use AI more next year. Business leaders need to embrace this speed and optimism to ensure that their companies don’t get left behind. Yet despite all the excitement and early experimentation, 47 percent of C-suite leaders say their organizations are developing and releasing gen AI tools too slowly, citing talent skill gaps as a key reason for the delay (Exhibit 6). Image description begins: The exhibit shows US C-suite executive sentiment toward the pace of development and release of gen AI tools within their organizations, in the form of two segmented bar charts. The first bar chart presents the overall perception of the pace, where 47 percent of respondents find the pace to be too slow, while 45 percent feel it is about right, and a smaller 9 percent consider it too fast. The second bar chart delves into the top reasons behind the perceived slow pace of gen AI tool development and release in executives&rsquo; organizations, focusing on the responses from those who indicated that development was too slow. The most prominent reason cited is talent skill gaps, accounting for 46 percent of these responses. Resourcing constraints followed closely, with 38 percent of respondents identifying this as a key factor. Complex approval process and technical complexity each receive 8 percent of the responses. Source: McKinsey US CxO survey, Oct-Nov 2024. This image description was completed with the assistance of Writer, a gen AI tool. Image description ends. Business leaders are trying to meet the need for speed by increasing investments in AI. Of the executives surveyed, 92 percent say they expect to boost spending on AI in the next three years, with 55 percent expecting investments to increase by at least 10 percent from current levels. But they can no longer just spend on AI without expecting results. As companies move on from the initial thrill of gen AI, business leaders face increasing pressure to generate ROI from their gen AI deployments. We are at a turning point. The initial AI excitement may be waning, but the technology is accelerating. Bold and purposeful strategies are needed to set the stage for future success. Leaders are taking the first step: One quarter of those executives we surveyed have defined a gen AI road map, while just over half have a draft that is being refined (Exhibit 7). With technology changing this fast, all road maps and plans will evolve constantly. For leaders, the key is to make some clear choices about what valuable opportunities they choose to pursue first—and how they will work together with peers, teams, and partners to deliver that value. Image description begins: The exhibit is comprised of two horizontal segmented bar charts. The first chart displays the share of US C-suite respondents who have a defined gen AI roadmap. 21 percent report not currently having a roadmap but one was in progress, 53 percent indicate having a roadmap that is still being refined, and 25 percent state that a comprehensive roadmap is already in place. The second bar chart illustrates the level to which US C-suite respondents have identified revenue-generating use cases for gen AI. 1 percent of respondents indicate they have not yet identified any such use cases, while 10 percent report they have minimally identified, 38 percent have partially identified, 39 percent have mostly identified, and 12 percent have fully identified such use cases. Source: McKinsey US CxO survey, Oct-Nov 2024. This image description was completed with the assistance of Writer, a gen AI tool. Image description ends The dilemma of speed versus safety There’s a spanner in the works: Regulation and safety often continue to be seen as insurmountable challenges rather than opportunities. Leaders want to increase AI investments and accelerate development, but they wrestle with how to make AI safe in the workplace. Data security, hallucinations, biased outputs, and misuse (for example, creating harmful content or enabling fraud) are challenges that cannot be ignored. Employees are well aware of AI’s safety challenges. Their top concerns are cybersecurity, privacy, and accuracy (Exhibit 8). But what will it take for leaders to address these concerns while also moving ahead at light speed? Image description begins: The exhibit shows the share of US employees with concerns regarding gen AI, through a series of proportional area charts, each representing a specific risk associated with gen AI. The size of each chart indicates the percentage of US employees who cite that risk as a concern. Cybersecurity risks are cited by 51 percent of respondents, inaccuracies by 50 percent, and concerns about personal privacy by 43 percent. Intellectual property infringement is a concern for 40 percent of respondents, followed by workforce displacement (35 percent), explainability (34 percent), and equity and fairness (30 percent). Less prominent but still significant concerns were regulatory compliance issues (28 percent), national security (24 percent), damage to organizational reputation (16 percent), environmental impact (15 percent), physical safety (14 percent), and political stability (13 percent). Source: McKinsey US employee survey, Oct&ndash;Nov 2024. This image description was completed with the assistance of Writer, a gen AI tool. Image description ends. Employees trust business leaders to get it right While employees acknowledge the risks and even the likelihood that AI may replace a considerable portion of their work, they place high trust in their own employers to deploy AI safely and ethically. Notably, 71 percent of employees trust their employers to act ethically as they develop AI. In fact, they trust their employers more than universities, large technology companies, and tech start-ups (Exhibit 9). Image description begins: The exhibit depicts the share of US employees who highly trust different institutions to deploy gen AI tools responsibly, safely, and ethically. The data is presented as four separate unit charts, each representing a distinct institution: employer, universities, large tech companies, and start-ups. Each unit chart consists of a 10x10 matrix of squares. The number of light blue squares within each grid represents the percentage of employees who express high trust in each institution. The remaining squares are light gray. Employers receive the highest level of trust (71 percent), followed by universities (67 percent), large tech companies (61 percent), and start-ups (51 percent). Source: McKinsey US employee survey, Oct&ndash;Nov 2024. This image description was completed with the assistance of Writer, a gen AI tool. Image description ends. According to our research, this is in line with a broader trend in which employees show higher trust in their employers to do the right thing in general (73 percent) than in other institutions, including the government (45 percent). This trust should help leaders act with confidence as they tackle the speed-versus-safety dilemma. That confidence also applies outside the United States, even though employees in other regions may have more desire for regulation (see sidebar “Global perspectives on regulation”). Sidebar Global perspectives on regulation A high percentage of international C-suite leaders we surveyed across five regions (Australia, India, New Zealand, Singapore, and the United Kingdom) are Gloomers, who favor greater regulatory oversight. Between 37 to 50 percent of international C-suite leaders self-identify as Gloomers, versus 31 percent in the United States. This may be because top-down regulation is more accepted in many countries outside the United States. Of the global C-suite leaders surveyed, half or more worry that ethical use and data privacy issues are holding back their employees from adopting gen AI. However, our research shows that attitudes about regulation are not inhibiting the economic expectations of business leaders outside the United States. More than half of the international executives (versus 41 percent of US executives) indicate they want their companies to be among the first adopters of AI, with those in India and Singapore being especially bullish (exhibit). The desire of international business leaders to be AI first movers can be explained by the revenue they expect from their AI deployments. Some 31 percent of international C-suite leaders say they expect AI to deliver a revenue uplift of more than 10 percent in the next three years, versus just 17 percent of US leaders. Indian executives are the most optimistic, with 55 percent expecting a revenue uplift of 10 percent or more over the next three years. Risk management for gen AI In Superagency , Hoffman argues that new risks naturally accompany new capabilities—meaning they should be managed but not necessarily eliminated. 15 Reid Hoffman and Greg Beato, Superagency: What Could Possibly Go Right with Our AI Future , Authors Equity, January 28, 2025. Leaders need to contend with external threats, such as infringement on intellectual property (IP), AI-enabled malware, and internal threats that arise from the AI adoption process. The first step in building fit-for-purpose risk management is to launch a comprehensive assessment to identify potential vulnerabilities in each of a company’s businesses. Leaders can then establish a robust governance structure, implement real-time monitoring and control mechanisms, and ensure continuous training and adherence to regulatory requirements. One powerful control mechanism is respected third-party benchmarking that can increase AI safety and trust. Examples include Stanford CRFM’s Holistic Evaluation of Language Models (HELM) initiative—which offers comprehensive benchmarks to assess the fairness, accountability, transparency, and broader societal impact of a company’s AI systems—as well as MLCommons’s AILuminate tool kit on which researchers from Stanford collaborated. 16 “MLCommons launches AILuminate, first-of-its-kind benchmark to measure the safety of large language models,” Business Wire, press release, December 04, 2024. Other organizations such as the Data &amp; Trust Alliance unite large companies to create cross-industry metadata standards that aim to bring more transparency to enterprise AI models. While benchmarks have significant potential to build trust, our survey shows that only 39 percent of C-suite leaders use them to evaluate their AI systems. Furthermore, when leaders do use benchmarks, they opt to measure operational metrics (for example, scalability, reliability, robustness, and cost efficiency) and performance-related metrics (including accuracy, precision, F1 score, latency, and throughput). These benchmarking efforts tend to be less focused on ethical and compliance concerns: Only 17 percent of C-suite leaders who benchmark say it’s most important to measure fairness, bias, transparency, privacy, and regulatory issues (Exhibit 10). Image description begins: The exhibit presents data on the utilization of benchmarks for gen AI tools among US C-suite executives. The exhibit is in two parts. The first part is a pie chart showing that 39 percent of respondents have benchmark standards for gen AI tools used by their employees. This indicates a significant minority of C-suite executives currently employ such standards. The second part of the exhibit is a horizontal bar chart displaying the benchmarks considered most important by the C-suite respondents. Performance-related benchmarks are deemed most important by 41 percent of respondents. Operational benchmarks follow closely behind, cited by 35 percent of participants. Ethical and compliance benchmarks are a lower priority, selected by 17 percent of the respondents, while other benchmarks account for only 7 percent of responses. This reveals a noteworthy disparity, suggesting C-suite leaders put a stronger emphasis on benchmarking the performance and operational aspects of AI rather than benchmarking ethical considerations. Source: McKinsey US CxO survey, Oct-Nov 2024. This image description was completed with the assistance of Writer, a gen AI tool. Image description ends. The focus on operational and performance metrics reflects the understandable desire to prioritize immediate technical and business outcomes. But ignoring ethical considerations can come back to haunt leaders. When employees don’t trust AI systems, they are less likely to accept them. Although benchmarks are not a panacea to eliminate all risk and can’t ensure that AI systems are fully efficient, ethical, and safe, they are a useful tool. Even companies that excel at all three categories of AI readiness—technology, employees, and safety—are not necessarily scaling or delivering the value expected. Nevertheless, leaders can harness the power of big ambitions to transform their companies with AI. The next chapter examines how. Chapter 4 Embracing bigger ambitions Most organizations that have invested in AI are not getting the returns they had hoped. They are not winning the full economic potential of AI. About half of C-suite leaders at companies that have deployed AI describe their initiatives as still developing or expanding (Exhibit 11). They have had the time to move further. Our research shows that more than two-thirds of leaders launched their first gen AI use cases over a year ago. This is a time when you should be getting benefits [from AI] and hope that your competitors are just playing around and experimenting. Erik Brynjolfsson, professor at Stanford University and director of the Digital Economy Lab at the Stanford Institute for Human-Centered Artificial Intelligence (HAI) Image description begins: The exhibit is a horizontally stacked bar graph that shows the percentage of C-suite respondents who describe their gen AI rollouts by maturity stages. 8 percent of respondents report their organizations are in the nascent stage, characterized by minimal gen AI initiatives with no significant impact on employee workflows. A significantly larger portion, 39 percent, describe their organizations as being in the emerging stage, where gen AI pilot projects are starting to show value. The developing stage, where gen AI implementation is changing certain workflows and increasing efficiency, accounts for 31 percent of respondents. 22 percent of respondents place their organizations in the expanding stage, indicating that gen AI is scaled across departments, transforming workflows, and enhancing operations. Finally, only 1 percent of C-suite respondents describe their gen AI rollouts as mature, meaning that gen AI is fundamentally changing how work is done and driving substantial business "
        }
      },
      {
        "url": "https://zylo.com/blog/ai-cost/",
        "title": "AI Pricing: What's the True AI Cost for Businesses in 2025?",
        "type": "article",
        "date": "2025-09-19 04:25:03 +00:00",
        "score": 3,
        "metadata": {
          "snippet": "3 days ago — According to Zylo's 2025 SaaS Management Index, organizations spent an average of $400k on AI-native apps. This is a 75.2% year-over-year ...",
          "domain": "zylo.com",
          "breadcrumb": "https://zylo.com › blog › ai-cost",
          "is_featured": false,
          "content": "Table of Contents Toggle How Much Does Artificial Intelligence Cost? Factors Impacting AI Costs AI Features and Functionalities Project Type and Scope Data Accessibility and Quality Labor and Expertise Infrastructure and Compute Resources Regulatory and Compliance Costs Project Duration and Management AI Pricing Trends to Watch in 2025 SaaS Premiums on AI-Enabled Features Rising Investment in AI-Native Applications Cloud-Based AI Pricing Models Open-Source AI and Cost Implications Subscription vs. One-Time Payment Models Increasing Complexity in AI Licensing AI Pricing Models Value-Based Pricing Buyer considerations: Usage-Based Pricing Key characteristics include: Buyer considerations: Subscription-Based Pricing Buyer considerations: Freemium Models Buyer considerations: Flat-Rate Pricing Buyer considerations: License Fee Models Buyer considerations: Performance-Based Pricing Key characteristics: Buyer considerations: Hybrid Pricing Models Buyer considerations: Labor Replacement Pricing Buyer considerations: Outcome-Based Pricing Key characteristics include: Buyer considerations: Blended Pricing Buyer considerations: Tiered Pricing Buyer considerations: Agentic Seat Pricing Key characteristics include: Buyer considerations: Cost-Plus Pricing Key characteristics include: Buyer considerations: Competitive Pricing Key characteristics include: Buyer considerations: Penetration Pricing Buyer considerations: How the Cost of AI Is Impacting Business Revenue\\ AI Costs in Relation to Business ROI Predictions for the Future of AI Pricing The Role of Innovation in Cost Reduction Effects of Market Competition Influence of Global Economic Factors AI Pricing and Compliance Pressure Zylo Helps You Understand the True Cost of AI Table of Contents Toggle How Much Does Artificial Intelligence Cost? Factors Impacting AI Costs AI Features and Functionalities Project Type and Scope Data Accessibility and Quality Labor and Expertise Infrastructure and Compute Resources Regulatory and Compliance Costs Project Duration and Management AI Pricing Trends to Watch in 2025 SaaS Premiums on AI-Enabled Features Rising Investment in AI-Native Applications Cloud-Based AI Pricing Models Open-Source AI and Cost Implications Subscription vs. One-Time Payment Models Increasing Complexity in AI Licensing AI Pricing Models Value-Based Pricing Buyer considerations: Usage-Based Pricing Key characteristics include: Buyer considerations: Subscription-Based Pricing Buyer considerations: Freemium Models Buyer considerations: Flat-Rate Pricing Buyer considerations: License Fee Models Buyer considerations: Performance-Based Pricing Key characteristics: Buyer considerations: Hybrid Pricing Models Buyer considerations: Labor Replacement Pricing Buyer considerations: Outcome-Based Pricing Key characteristics include: Buyer considerations: Blended Pricing Buyer considerations: Tiered Pricing Buyer considerations: Agentic Seat Pricing Key characteristics include: Buyer considerations: Cost-Plus Pricing Key characteristics include: Buyer considerations: Competitive Pricing Key characteristics include: Buyer considerations: Penetration Pricing Buyer considerations: How the Cost of AI Is Impacting Business Revenue\\ AI Costs in Relation to Business ROI Predictions for the Future of AI Pricing The Role of Innovation in Cost Reduction Effects of Market Competition Influence of Global Economic Factors AI Pricing and Compliance Pressure Zylo Helps You Understand the True Cost of AI Updated September 19, 2025 – This article has been revised to include up-to-date AI pricing models, recommendations, and predictions. AI adoption has skyrocketed. But when it comes to pricing, it’s like opening Pandora’s Box. It’s inconsistent, complex, and constantly evolving. As AI becomes embedded into nearly every SaaS platform, understanding the true cost of artificial intelligence is no longer optional—it’s essential to controlling software spend in 2025 . How Much Does Artificial Intelligence Cost? According to Zylo’s 2025 SaaS Management Index, organizations spent an average of $400k on AI-native apps. This is a 75.2% year-over-year increase , indicating AI costs will continue growing. The question “How much does AI cost?” doesn’t have a single answer. AI pricing varies based on: Vendor pricing models (subscription, usage-based, flat-rate) Deployment model (cloud-based, hybrid, on-premise) Type of AI functionality (embedded vs native AI applications) Infrastructure and compute resource demands Required level of customization and integration AI costs can range from a few dollars per user to hundreds of thousands in annual spend. Depending on your AI strategy, that cost could be small and incremental, or it could be significant and complex to manage. Take Microsoft Copilot, for example. It’s priced at $30 per user, per month—but only if you already have a Microsoft 365 license. That makes the actual cost significantly higher. In contrast, applications like Salesforce Agentforce and ChatGPT are consumption-based, charging a set rate per conversation or token. The more you prompt and output, the more you pay. These usage- and outcome-based models add complexity to forecasting and make budgeting less predictable. In fact, 65% of IT leaders Zylo surveyed reported unexpected charges on SaaS due to consumption-based or AI pricing models. Factors Impacting AI Costs While pricing models define how vendors charge for AI, the actual cost of deploying and managing AI hinges on these key factors: The complexity and scope of your AI initiative Labor and infrastructure required to build and maintain models Quality, availability, and volume of data used How you deploy and scale AI across the organization Regulatory and compliance overhead tied to industry or geography These factors span from the intrinsic AI features to the external requirements that drive the overall investment. AI Features and Functionalities The more advanced the capabilities, the higher the cost. AI-native tools with capabilities like generative text, computer vision, or autonomous decision making require significantly more compute power and often command premium pricing. For example, AI models with natural language processing , image generation, or real-time translation typically rely on high-cost GPU infrastructure and substantial development. Project Type and Scope AI use cases range from simple automations to enterprise-wide deployments. A narrow, internal-use chatbot costs far less than a fully integrated AI engine powering customer-facing applications. Custom AI projects also require longer development cycles, testing, and dedicated engineering resources—all of which increase total cost of ownership. Data Accessibility and Quality Poor data quality is one of the most common and costly blockers to AI success. Without access to clean, labeled, and structured data, model training becomes inefficient and expensive. Investments in data cleaning, tagging, governance, and integration with existing systems are often required before AI initiatives can scale. Labor and Expertise Skilled AI practitioners don’t come cheap. From data scientists to ML engineers, the talent needed to build, deploy, and refine AI models adds significant cost. In many cases, companies must also invest in upskilling their current workforce to maintain or manage AI systems. Infrastructure and Compute Resources Training AI models, particularly those based on deep learning or generative AI, requires significant compute resources . That means investment in: GPUs or cloud-based compute clusters Storage for large datasets Scalable deployment environments The rise of consumption-based pricing in cloud platforms (e.g., per hour or per token) can further inflate operational costs as usage increases. Regulatory and Compliance Costs AI systems that process sensitive data must comply with privacy regulations such as GDPR, HIPAA, and others. Maintaining compliance can add cost via: Data residency requirements Explainability and audit tools Legal review and risk assessments Security controls and breach response capabilities As AI governance evolves , so will the cost of staying compliant, especially in regulated industries like healthcare, finance, or government. Project Duration and Management Even the most promising AI initiatives can run over budget if timelines extend due to poor planning, team misalignment, or shifting business requirements. Many organizations underestimate the need for robust project management and stakeholder engagement, two critical levers in avoiding scope creep and budget bloat. AI Pricing Trends to Watch in 2025 In 2025, we expect AI costs to be shaped by: Premium pricing for AI-enabled features in traditional SaaS tools Rising enterprise investment in AI-native platforms More granular, usage-based billing (per task, token, or conversation) Increasing reliance on open-source AI frameworks — with hidden costs Growing confusion around licensing, renewals, and total cost of ownership AI pricing models are evolving faster than buyers can keep up. OpenAI’s CEO, Sam Altman , predicted that “AI prices will drop 10x annually,” but we’re seeing the opposite in the short term, especially among enterprise vendors. For instance, Microsoft added Copilot to Microsoft 365 and raised subscription prices. Meanwhile, Google adjusted Workspace pricing and embedded AI at no added cost. These contrasting strategies reflect a broader trend: AI is becoming table stakes, but not every vendor agrees on how to price it. SaaS Premiums on AI-Enabled Features Vendors are charging more for AI, often by bundling features into higher-tier plans, regardless of usage or value. This trend is pushing many organizations into more expensive SKUs without a clear business case or proven adoption. Teams are struggling to justify these added costs, especially when: AI capabilities are underused or sit idle due to lack of enablement Visibility into AI usage and value is limited Functionality is bundled with other tools the business doesn’t need In many cases, AI features are included as line items in renewals without clear ROI tracking or accountability. This leads to waste, especially in environments where feature usage is unknown or misaligned with team needs. Rising Investment in AI-Native Applications AI-native tools are seeing rapid adoption and growing budget share, but many still lack the enterprise controls needed to manage them effectively. These applications are built around AI from the start, and their appeal is driving organic growth across departments. One clear signal: ChatGPT became the #2 most-expensed app by number of transactions, up from #14 the year before. That rise reflects a broader shift toward individual users introducing AI tools into their daily workflows, often without IT involvement. The result is a growing set of tools that are: Purchased outside of procurement Disconnected from centralized license management Lacking in usage governance or security review This makes it difficult for organizations to understand what’s being used, who’s using it, and how much it’s costing. Without a system of record or ownership model, AI-native tools can quickly drive up spend and create risk, even when they offer real productivity value. Cloud-Based AI Pricing Models Usage-based pricing has become the norm for cloud-delivered AI, and it&#8217;s introducing budget uncertainty for IT, finance, and procurement. Vendors are shifting away from flat-rate pricing in favor of models that charge based on activity, not access. This trend aligns pricing with real-time usage but creates volatility across the organization. Key challenges with cloud-based AI pricing: Unpredictable billing: Pricing is often based on variables like time used, tokens consumed, or data processed, which are difficult to estimate upfront. Delayed visibility: Finance and procurement teams frequently aren’t notified until after charges are incurred, making it harder to forecast or allocate spend accurately. No clear usage thresholds: AI tools may lack built-in usage caps or alerts, leading to overages that surprise IT leaders and budget owners. Poor integration with existing governance tools: Many AI platforms don’t plug into current SaaS Management systems, leaving teams blind to usage trends or contract changes. Adding to the complexity, a growing number of AI vendors are layering multiple pricing models into their platforms. According to High Alpha , nearly half of AI vendors rely on hybrid pricing models, combining subscription fees with usage-based or value-based charges. This means buyers aren’t just managing one pricing structure. They’re navigating two or more per contract. Open-Source AI and Cost Implications Open-source models like LLaMA and Mistral are gaining traction, especially among technical teams. But “free” isn’t always cheaper. Deploying open-source AI at scale still requires: Hosting and infrastructure (e.g., GPUs, cloud clusters) DevOps resources for deployment and monitoring Security and compliance oversight Ongoing model tuning and performance management Without governance, open-source AI can create silos and shadow systems that bypass existing purchasing and security protocols, leading to surprise costs down the road. Subscription vs. One-Time Payment Models While subscription pricing still dominates, some vendors are testing alternatives to meet buyer demand for predictability. Subscription models offer: Lower upfront cost Continuous access to updates and new features Greater flexibility for scaling up/down One-time licenses offer: Long-term budget stability Lower total cost over time Simplified procurement and renewals The trade-off? One-time licenses often require longer commitments and may lack portability across teams or business units. Increasing Complexity in AI Licensing AI licensing complexity affects everything from vendor selection to renewal negotiations. It also makes it harder to: Understand what you’re paying for Forecast true usage across teams Align pricing with value delivered Prevent exposure to shadow AI risk Drive user adoption Vendors are introducing layered entitlements, microservices, AI usage thresholds, and bundled SKUs that vary by user, region, or function. As Zylo Co-founder Ben Pippenger describes it, “every app has its own flavor,” highlighting how even major vendors like Salesforce and Zendesk now layer usage-based fees onto traditional per-seat contracts. AI Pricing Models AI vendors are using a variety of pricing models to monetize functionality, scale, and outcomes. Common AI pricing models include: Value-based pricing Usage-based pricing Subscription-based pricing Freemium models Flat-rate pricing License Fee models Performance-based pricing Hybrid pricing models Labor replacement pricing Outcome-based pricing Blended pricing Tiered pricing Agentic seat pricing Cost-Plus pricing Competitive pricing Penetration pricing Understanding the structure behind each model is key to evaluating cost, forecasting spend, and aligning pricing with value delivered. Value-Based Pricing Value-based pricing ties the cost of AI to the perceived or delivered value, rather than usage or features. Key characteristics include: Pricing is set based on ROI potential, business impact, or competitive advantage Often used in vertical-specific tools (e.g., healthcare, finance, sales performance) Requires vendors to articulate and prove value over time This model is common for vendors positioning AI as a strategic differentiator or performance driver. The logic: the more business value the AI tool delivers, the more a buyer should be willing to pay. Buyer considerations: Hard to forecast: Without clear value metrics, pricing may feel subjective or unstable Negotiation-heavy: Contracts often depend on stakeholder alignment, use case complexity, and expected outcomes High expectations: Buyers will expect measurable performance improvements to justify cost Usage-Based Pricing Usage-based pricing charges based on how much of the AI service you consume, often by: Tokens API calls Resolutions Hours Other unit-based metrics Key characteristics include: Pricing is tied directly to activity: prompts, responses, conversations, compute time, etc. Enables low-cost entry points with scalable spend as adoption increases Often used by API-first or infrastructure-based AI vendors This model is common for generative AI platforms, APIs, and cloud-hosted services. The more you use, the more you pay. Buyer considerations: Difficult to predict spend: Especially early in deployment or during usage spikes Lacks guardrails: Many tools don’t have caps, alerts, or thresholds to prevent runaway usage Cross-team coordination required: Finance, IT, and business units must align to track and control consumption Subscription-Based Pricing Subscription-based pricing charges a recurring fee (typically monthly or annually) for access to an AI product or service. Key characteristics include: Fixed fee per user, seat, or license over a defined period Common for AI add-ons in enterprise software (e.g., Microsoft Copilot) Often bundled into higher-tier plans with additional functionality Buyer considerations: Predictable billing: Easier to forecast and allocate budgets May lead to overpayment: If AI functionality is underused or sits dormant Important to monitor value delivered: Especially for bundled features where AI is not the core driver Freemium Models Freemium pricing offers basic access to an AI product for free with advanced features, usage limits, or business capabilities gated behind a paid tier. Key characteristics include: Free tier includes limited functionality, usage volume, or output Premium tiers unlock enhanced features, enterprise controls, or support Often seen in AI-native tools targeting individual users or SMBs Freemium is commonly used to drive user adoption and upsell to premium plans. It works best for viral tools or self-serve onboarding models. Buyer considerations: Low barrier to entry: Great for testing but often lacks governance controls Sprawl risk: Employees may adopt AI tools without procurement or IT involvement Upgrade pressure: Free plans are often structured to push users into paid tiers quickly Flat-Rate Pricing Flat-rate pricing charges a fixed cost for unlimited access to the AI product or service, regardless of usage volume. Key characteristics include: One price for all users or an entire organization Typically includes unlimited usage within defined terms Rare among infrastructure-heavy or generative AI tools due to compute costs This model offers simplicity and cost predictability but can misalign pricing and value if usage varies widely. It’s most common in early-stage tools or bundled offerings where usage is difficult to meter. Buyer considerations: Predictable spend: Easier for budgeting and procurement approval Potential overpayment: Light users may pay disproportionately compared to value received Lacks incentives for optimization: No built-in feedback loop between usage and cost License Fee Models License fee pricing involves a one-time or recurring payment to access an AI product under a defined usage agreement. Key characteristics include: Fee is tied to the right to use the software, not the volume of use May be perpetual (one-time) or time-limited (renewed annually) Often found in regulated or highly customized environments This model is often used for on-premises or enterprise-grade deployments where long-term access is required. It provides buyers with more ownership but also more responsibility for management and maintenance. Buyer considerations: Higher upfront cost: May require CapEx approval or longer procurement cycles More control: Useful for organizations that need local deployment or custom environments Governance needed: Buyers must track entitlements, renewal dates, and contract terms Performance-Based Pricing Performance-based pricing ties cost directly to the results an AI product delivers, such as Increased sales Reduced errors Time saved Key characteristics: Pricing is triggered by KPIs, milestones, or performance benchmarks Common in AI tools for sales, marketing, and operations optimization Typically includes clear SLAs or outcome definitions in the contract You pay only when the AI meets predefined success metrics. This model aligns pricing with business outcomes, but requires strong measurement frameworks. Buyer considerations: Aligned incentives: Vendors are motivated to deliver measurable results Requires data transparency: Both sides need access to outcome metrics Complex to negotiate and enforce: May involve custom contracts and legal review Hybrid Pricing Models Hybrid pricing combines two or more pricing models. Most commonly, that’s a base subscription plus usage-based or performance-based components. Key characteristics include: Fixed fee covers baseline access or functionality Variable charges apply based on usage, outcomes, or premium features This is increasingly common among AI vendors looking to balance predictable revenue with scalable pricing. It offers flexibility but adds complexity for both buyers and finance teams. Buyer considerations: Harder to forecast: Monthly invoices may vary widely depending on usage Requires close monitoring: Usage tracking and contract transparency are essential May blur value alignment: Buyers must separate baseline cost from variable performance Labor Replacement Pricing Labor replacement pricing is based on the cost savings associated with automating tasks traditionally done by humans. Key characteristics include: Pricing reflects full or partial replacement of manual labor Framed around cost-per-agent, cost-per-hour, or FTE equivalency Common in agentic AI tools (e.g., AI chatbots, virtual assistants) This model positions AI as a direct substitute for headcount and prices accordingly. lt is often used to justify high-value AI tools in customer service, content creation, or administrative workflows. Buyer considerations: Strong ROI narrative: Easy to justify if headcount reduction or capacity gains are realized Can oversimplify value: Not all labor replaced equals the same business impact Ethical and cultural concerns: May raise internal questions about workforce impact Outcome-Based Pricing Outcome-based pricing charges only when the AI delivers a defined business result, such as: Conversions Leads generated Fraud prevented Time saved Key characteristics include: Pricing is activated only when specific outcomes are achieved Common in high-stakes AI use cases like revenue generation or cost avoidance Requires detailed metrics, tracking, and agreed-upon definitions of “success” It’s similar to performance-based pricing but typically tied to a more specific, quantifiable outcome. This model transfers more risk to the vendor and aligns cost directly with value delivered. Buyer considerations: Aligned with results: Easier to justify budget when payment follows value Complex to structure: Requires legal and operational clarity on what counts as a “successful” outcome Longer sales cycles: Often involves more negotiation and customization Blended Pricing Blended pricing averages multiple pricing models into a single, simplified rate, such as combining subscription and usage costs into a flat monthly fee. Key characteristics include: Combines elements of usage-based, subscription, or performance-based pricing Packaged as a single monthly or annual fee for simplicity Often the result of negotiated enterprise agreements Blended pricing is designed to reduce complexity for the buyer while giving vendors flexibility in monetization. It is common in mid-market and enterprise contracts where standard pricing doesn’t cleanly fit the use case. Buyer considerations: Easier to forecast: Consolidates multiple pricing inputs into a predictable number May obscure true usage: Without detailed reporting, buyers may lose insight into what’s driving cost Important to validate assumptions: Blended rates should reflect real-world usage patterns to avoid overpaying Tiered Pricing Tiered pricing offers different levels of access or functionality at progressively higher price points. Key characteristics include: Pricing tiers are predefined (e.g., Basic, Pro, Enterprise) Each tier unlocks additional features, usage capacity, or support levels Common in PLG (product-led growth) or self-service models This model is designed to support scalability while nudging customers toward higher-value plans. It is frequently used for both AI-native tools and AI add-ons in larger platforms. Buyer considerations: Easy to understand: Clear upgrade paths make planning and comparison easier Can lead to upsell pressure: Vendors often gate key AI features behind higher tiers Watch for shelfware risk: Higher tiers may include features your team won’t use Agentic Seat Pricing Agentic seat pricing charges per AI “agent” or bot, similar to how traditional SaaS charges per user. Each seat represents a distinct AI worker with specific responsibilities or workflows. Key characteristics include: Pricing is based on the number of AI agents deployed Each agent may have its own permissions, use cases, or integrations Common in AI tools for customer support, sales enablement, or task automation Buyer considerations: Aligns with headcount thinking: Easy to model if agents replace or augment human roles Can grow fast: More agents = more cost, especially if provisioned without governance Requires role clarity: Define what each agent does and track usage to avoid overprovisioning Cost-Plus Pricing Cost-plus pricing sets the AI product price based on the vendor’s internal costs plus a fixed profit margin. It’s less common in commercial SaaS but may appear in highly customized or services-heavy AI engagements. Key characteristics include: Pricing includes costs like compute, data labeling, infrastructure, and support Profit margin is added as a percentage markup More common in consulting-heavy AI implementations or bespoke model training Buyer considerations: Transparent but inflexible: Doesn’t scale well with actual usage or performance Not value-aligned: You may pay more even if business impact is limited Useful for custom builds: Works best when outcomes are unpredictable and vendor cost is the primary risk Competitive Pricing Competitive pricing sets the AI product’s cost based on market rates, focused on winning market share—especially in crowded or early-stage AI categories. Key characteristics include: Prices are benchmarked against similar tools or features May be temporary or used during promotional periods Common in categories like AI transcription, summarization, or copilots Buyer considerations: Easy to compare: Helpful when evaluating multiple AI vendors May sacrifice depth or support: Lower prices can mean fewer enterprise features or service guarantees Watch for post-promotion increases: Vendors may shift to hybrid or value-based models after adoption Penetration Pricing Penetration pricing sets a deliberately low entry price that’s more of a growth tactic, not a long-term pricing strategy. Key characteristics include: Introductory pricing is lower than market value Aims to remove cost as a barrier to adoption Often accompanied by aggressive free trials or discounts Buyer considerations: Short-term benefit: Good opportunity to test value with low risk Expect future increases: Pricing typically rises as features expand or usage grows Read contracts carefully: Confirm whether introductory rates are time-limited or usage-capped How the Cost of AI Is Impacting Business Revenue\\ Rising AI costs are starting to cut into margins and influence how companies think about growth. While AI can streamline work, the expense tied to consumption and licensing often offsets gains if adoption isn’t carefully managed. Revenue impacts of AI costs: Margin pressure: Expensive AI features bundled into SaaS tools can raise contract values without proportional revenue lift. Throttled adoption: Usage-based pricing causes some teams to limit AI usage, reducing the potential for productivity gains that could drive top-line growth. Competitive imbalance: Companies that can absorb higher AI costs may outpace peers, widening the performance gap. Forecasting challenges: Unpredictable spend makes it harder to project financial outcomes tied to AI initiatives. In short, while AI promises revenue acceleration , its evolving pricing models are just as likely to compress margins or create unplanned spend. Organizations that lack oversight risk eroding the very financial outcomes AI is meant to enhance. AI Costs in Relation to Business ROI AI spend only drives ROI when it is directly connected to measurable business outcomes. Without governance, usage tracking, and clear KPIs, AI often becomes a cost center instead of a value driver. ROI considerations for AI: Adoption vs. spend: Licenses and credits only matter if employees are actively using the tools. Direct vs. indirect benefits: Revenue gains (e.g., more deals closed) are easier to measure than indirect savings (e.g., time saved). Governance requirements: ROI depends on monitoring usage, aligning spend with strategy, and reducing waste. Risk of overinvestment: Without benchmarks, organizations may overspend on tools that deliver minimal value. The challenge is turning potential into measurable outcomes. Companies must establish KPIs tied to productivity, efficiency, or revenue impact, and regularly assess whether AI tools are meeting them. By linking cost directly to performance, organizations can separate true value from hype-driven spend. Predictions for the Future of AI Pricing AI pricing will continue to evolve through 2025 and beyond. Here are a few predictions for how we think it will shape up: Innovation will reduce some costs, but enterprise-grade AI will remain expensive Market competition will introduce new pricing models and drive price pressure Global economic conditions will influence how quickly companies invest Compliance requirements will add new layers of cost and complexity Organizations must prepare for continued change and uncertainty, with governance frameworks in place to track spend and align it with measurable outcomes. The Role of Innovation in Cost Reduction Innovation may help lower certain AI costs over time, such as infrastructure or model training. But enterprise-grade AI will remain capital-intensive. As Sam Altman noted, building and operating AI is one of the most expensive undertakings in Silicon Valley. This means vendors will continue to pass costs on to customers, even as efficiency improves. Effects of Market Competition Competition is already driving variety in pricing. Vendors are experimenting with freemium, usage-based, and outcome-based models to capture market share. Over time, this competition may push prices down. But it’s just as likely to create more complexity, with buyers managing multiple pricing structures across tools. Influence of Global Economic Factors Macroeconomic pressures such as inflation, interest rates, and global tech investment will directly affect how quickly organizations adopt AI. In tighter markets, companies may be more cautious about experimenting with AI tools that lack clear ROI. AI Pricing and Compliance Pressure Regulatory changes are expected to increase costs. From privacy requirements like GDPR to emerging AI-specific governance frameworks, compliance will require new investments in auditability, explainability, and risk management. These costs will be baked into AI pricing, raising the total cost of ownership for buyers. Zylo Helps You Understand the True Cost of AI AI costs are difficult to manage without visibility. Zylo makes it simple. With Zylo’s Discovery and Inventory solution, you can see every SaaS and AI tool in use, track adoption, uncover hidden spend, and ensure investments align with business priorities. Contact Zylo for a demo and take control of your AI spending. This article is brought to you by Zylo – the enterprise leader in SaaS Management. Companies such as AbbVie, Adobe, Atlassian, Intuit, Salesforce, and Yahoo leverage Zylo’s AI-powered platform and unparalleled professional services to fuel centralized SaaS inventory , license optimization , and renewal management . AI Costs, AI Pricing, Consumption-Based Pricing"
        }
      },
      {
        "url": "https://www.cloudzero.com/state-of-ai-costs/",
        "title": "The State Of AI Costs In 2025",
        "type": "article",
        "date": "2025-09-22T04:25:05.036Z",
        "score": 2,
        "metadata": {
          "snippet": "AI spending is surging — average monthly AI budgets are set to rise by 36% in 2025, reflecting a major shift toward larger, more complex AI initiatives. Only 51 ...",
          "domain": "www.cloudzero.com",
          "breadcrumb": "https://www.cloudzero.com › state-of-ai-costs",
          "is_featured": false,
          "content": "2025 Report The State Of AI Costs In 2025 We surveyed 500 engineering professionals on the state of their AI costs in 2025. Here&#8217;s what we found &#8230; Table Of Contents AI budget allocation and spending trends Tracking AI costs and measuring ROI The key factors driving AI spending The most used AI tools, platforms, and services The AI talent landscape: salaries, skills and staffing struggles Conclusion: AI innovation must be paired with cost intelligence Methodology Artificial intelligence (AI) has become a cornerstone of modern business strategy, powering innovation, efficiency, and growth across industries. From intelligent automation to machine learning at scale, AI is transforming how organizations operate and deliver value. However, as AI adoption accelerates, a new challenge has emerged: managing the rapidly growing costs of AI in a scalable and intelligent way. Businesses must balance the transformative potential of AI with growing pressure to optimize spending, control cloud costs, and ensure long-term profitability. To uncover how companies navigate this complex landscape, we surveyed 500 software engineers at the manager level and above across the U.S. This report explores how organizations are budgeting for AI, where they’re investing, and what’s standing in the way of achieving true AI return on investment (ROI). Our findings reveal a heady but volatile dynamic. AI momentum and budgets grow rapidly, as do organizations’ confidence in its value — however, organizations report misalignment, limited AI governance, and difficulty calculating AI ROI. As cloud-based AI tools consume the lion’s share of budgets, cost visibility and attribution have become essential. Without these, even the most ambitious AI strategies risk becoming unpredictable and unsustainable. Key Takeaways AI spending is surging — average monthly AI budgets are set to rise by 36% in 2025, reflecting a major shift toward larger, more complex AI initiatives. Only 51% of organizations can confidently evaluate AI ROI , highlighting a growing visibility gap. At the same time, the dominance of cloud-based tools makes cloud cost visibility and attribution crucial for optimizing AI ROI. Organizations using third-party cost optimization tools report stronger ROI confidence , signaling the need for better observability. The most widely used AI tools are designed for automation, scalability, and cloud deployment — but without effective cost tracking, their profitability remains uncertain. Cloud computing and data engineering are the most in-demand AI skills , while high salary expectations and a lack of internal expertise to evaluate candidates are the greatest challenges in AI hiring. 01 AI budget allocation and spending trends Monthly AI budgets are on the rise in 2025 In 2024, the average monthly spend on AI was $62,964, which our findings suggest will rise to $85,521 in 2025 (a 36% increase). Notably, the proportion of organizations planning to invest over $100,000 per month in AI tools is set to more than double, jumping from 20% in 2024 to 45% in 2025. This surge in spending suggests businesses are ramping up their AI initiatives to drive greater efficiency, fuel innovation, and maintain a competitive edge. But as budgets rise, organizations must face a critical question: Are we confident in the return we’re getting from our AI investments ? Share Download Expand Share Download Share Download Expand Share Download Public cloud platforms receive the highest AI budget allocation Companies are strategically investing in AI, with public cloud platforms receiving the largest share of AI budgets (11%), showing their role in scaling AI workloads. Generative AI tools follow at 10%, reflecting their growing impact on innovation and operations. Security platforms account for 9% of budgets, highlighting concerns around protecting AI systems. Hybrid cloud and AI-specific platforms see moderate investment, balancing flexibility with specialization. When it comes to future AI budgeting, we know that the majority of companies intend to scale up their AI spend in 2025. But which areas in particular are they planning to prioritize for spending over the next 12 months? Share Download Expand Share Download Nearly half of companies plan to prioritize AI explainability In 2025, 44% of organizations plan to invest in improving AI explainability, aiming to boost transparency and accountability in AI systems, making AI models more understandable to users by clarifying how decisions are made. This investment often takes the form of hiring specialized talent and integrating third-party tools that provide model interpretability. Beyond explainability, the top areas organizations plan to prioritize in thecoming year include AI security and robustness (41%), cloud and computing resources (39%), and improving customer experience (39%). These focus areas signal a broader shift toward more responsible, transparent, and scalable AI deployment. While explainability leads the pack, the overall distribution of budget priorities suggests a relative parity across categories, organizations are committing investment across a wide range of AI capabilities, indicating a holistic approach to AI maturity. Large enterprises are prioritizing new AI initiatives, while smaller companies focus on cloud resources The focus of future AI investments varies significantly depending on company size. Larger companies (10,000+ employees) are particularly focused on scaling AI adoption, with half prioritizing new AI initiatives and 43% investing in training their employees in AI. This reflects their strategic emphasis on expanding AI capabilities across the organization. In contrast, mid-sized companies (1,001 to 10,000 employees) are channeling substantial resources into cloud and computing infrastructure, with 54% investing heavily in scalable AI solutions to support their growing needs. Smaller companies (250 to 500 employees) are also focused on cloud and computing resources, but at a lower rate of 38%. Share Download Expand Share Download Key takeaways $85,521 Average monthly spend on AI 36% Average increase in year-to-year AI spend 43% Organizations planning to spend $100,000 or more per month on AI 12% Of AI budgets are allocated to public cloud platform 02 Tracking AI costs and measuring ROI As AI adoption grows, managing costs is becoming more complex. Cloud computing, model training, and AI applications can drive expenses up quickly, requiring more than simply tracking spend. Yet, for many organizations, accurately tracking these costs and evaluating AI return on investment (ROI) remains a major challenge. Why ROI measurement is difficult Understanding AI-driven revenue is key for businesses to justify investments, assess effectiveness, and prioritize high-return projects. However, accurately measuring ROI remains a challenge for many companies. Common obstacles include: Difficulty in isolating AI’s impact from other business factors Difficulty attributing AI costs to the correct sources Long implementation timelines before seeing tangible results Hidden costs such as cloud expenses and maintenance As a result, only 51% of organizations strongly agree they can track AI ROI effectively, even though 91% claim overall confidence in their ability to evaluate it. This gap between perception and precision reveals a need for more robust cost attribution and tracking methods. Tooling gaps undermine cost visibility We found some big variations in how companies track their AI spending depending on their size. While large companies lean heavily on vendor-native tools (79%), many lack the granular cost attribution that third-party platforms provide. Without complete cost allocation (to get cost per feature, product, team, customer, microservice, etc.), it’s impossible to know exactly who or what is driving which costs and, by extension, how to hold them accountable. We also found that 21% of larger companies don’t have any formal cost-tracking systems in place — meaning they stand the risk of overspending on AI without clear visibility into where their budget is going. Meanwhile, mid-sized companies are the biggest users of third-party cost monitoring tools (64%). Manual tracking prevails — but at a cost While 65% of companies use native tools and 54% use third-party platforms, many still rely on spreadsheets (57%) or consultants (41%) as core cost management methods. Further, a concerning one in six (15%) companies admitted to not having any formal cost-tracking system in place. This points to a clear opportunity: organizations should move beyond reactive methods and adopt scalable cost visibility systems to control spending, improve efficiency, and maximize ROI. Confidence in ROI correlates with cost optimization tools More than 90% of companies using third-party platforms, like CloudZero , reported high awareness of AI-driven revenue. This enables them to directly compare revenue and cost, resulting in highly reliable ROI calculations. On the other hand, organizations without any formal cost-tracking system in place are far less confident in their ability to accurately evaluate the ROI of AI initiatives. 41% indicated that they only “somewhat agree” that they can do this, highlighting the importance of adopting formal, reliable cost-tracking systems to accurately evaluate ROI. Share Download Expand Share Download Key takeaways 15% Companies with no AI cost tracking in place 57% Manually track AI costs 90% Confidence in cost tracking when using third-party systems 03 The key factors driving AI spending In this section, we’ll explore the primary factors influencing AI spending. Understanding these key drivers will provide insight into why organizations are prioritizing AI and how they are allocating their budgets to maximize value. More companies are investing in AI for internal efficiencies rather than market differentiation We found that the top three reasons organizations are investing in AI in 2025 are: To enhance software development efficiency (41%) To enhance cybersecurity and compliance (40%) To drive innovation and competitive advantage (37%) These drivers indicate a strong focus on productivity, security, and market differentiation. More organizations are prioritizing AI investments for internal efficiencies rather than for competitive advantage. This focus on operational improvements aligns with findings that 92% of respondents believe AI enhances team workflow and efficiency, and 87% rely on AI tools to perform their jobs effectively. Share Download Expand Share Download Top three reasons organizations are investing in AI 41% To enhance software development efficiency 40% To enhance cybersecurity and compliance 37% To drive innovation and competitive advantage 04 The most used AI tools, platforms, and services Cloud-based AI development dominates. The tools most commonly adopted are built for scalability, automation, and rapid deployment, which means they’re typically hosted in the cloud. This reflects the foundational role cloud infrastructure plays in modern AI strategies. Its scalability and compute power are essential for running advanced models and processing massive datasets. But while cloud services are indispensable, they also introduce complexity. As shown in our 2024 State of Cloud Cost report, 58% of companies believe their cloud costs are too high, a concern that only intensifies with AI adoption. Cost attribution, allocation, and real-time visibility aren’t just nice to have — they’re essential. Without them, organizations risk overspending, under-optimizing, and losing strategic control over their growing AI investments. Generative AI tools: Widespread but expensive Generative AI is the most widely used category (60%), but it can also introduce the highest costs due to compute-heavy inference, tokenized API pricing, and retraining overhead. Companies must carefully monitor these expenses across features and business units. Public and hybrid cloud usage is widespread — but cost efficiency varies More than half of organizations (55%) use the public cloud, while 51% rely on a hybrid cloud setup. Cloud is the backbone of AI. However, overprovisioning, idle resources, and poorly optimized configurations remain common. Without proactive optimization, cloud costs become a tax on innovation. Security and compliance: a costly necessity Over half (51%) of organizations are investing in AI-driven security tools for threat detection, compliance monitoring, and data protection — critical for safeguarding modern infrastructure, especially as cloud-based AI workloads grow more complex and exposed to risk. As investment in AI security grows, so does the risk of inefficiency. Companies must be cautious of overlapping tools, redundant configurations, and compliance workflows that silently drive up costs. Balancing robust protection with cost-effective operations is essential, especially in heavily regulated industries where both technical and financial stakes are high. Customer-facing applications and data engineering tools are major AI cost centers Half of the organizations surveyed invest in AI-powered applications (such as chatbots) and data analytics solutions, both of which can generate high cloud costs due to large-scale processing and inference workloads. These tools require significant computing power to analyze vast amounts of data in real time, often leading to unpredictable expenses. Share Download Expand Share Download Key takeaways 60% Have adopted generative AI tools 55% Have adopted public cloud platforms 51% Have adopted security platforms 05 The AI talent landscape: salaries, skills and staffing struggles Here, we’ll explore the data on the salary ranges for AI developers and professionals within organizations. AI adoption is driving job creation — but also driving concerns of job losses AI is reshaping the workforce, with 89% of companies reporting new roles emerging from automation and productivity gains, yet 62% remaining concerned about job displacement. This shows the need to balance innovation with reskilling to navigate the evolving job landscape. Cloud computing and data engineering are the most in-demand skills for AI roles When it comes to skills, cloud computing (57%) and data engineering (56%) are most in-demand. Cloud computing is in highest demand in larger companies (5,001+ employees), peaking at 71% for the 5,001 to 10,000 employee range. Meanwhile, data engineering is most sought after in mid-sized firms (501 to 5,000 employees) but less so in larger firms. As AI investments grow, expertise in cloud platforms and data engineering is key to optimizing performance and integration. AI salaries are soaring, with most AI professionals earning between $100,000 and $200,000 Most AI professionals earn over $100,000, with 26% earning between $150,000 and $200,000. Salaries are typically highest in large enterprises, but smaller companies often offer competitive pay to attract talent, especially in the $125,000 to $200,000 range. The greatest challenges in AI hiring One of the greatest challenges in AI hiring is high salary expectations. Smaller companies struggle with this the most, with 40% facing this issue, while only 29% of larger firms report the same challenge. There also appears to be a shortage of qualified candidates due to high demand, especially for mid-sized companies, with 40% struggling to find skilled professionals. Thirdly, a key hiring challenge is the lack of internal expertise to assess AI candidates, particularly in companies with 1,001 to 5,000 employees (17%), compared to 14% in smaller firms and just 7% in much larger companies. Share Download Expand Share Download Conclusion: AI innovation must be paired with cost intelligence AI is a transformative force. But transformation without control is unsustainable. Without effective cost governance, even the best AI initiatives can become financially inefficient. Our report highlights the need for organizations to go beyond tracking AI spend to actively optimizing it through real-time visibility, cost attribution, and actionable insights. With cloud-based AI tools comprising nearly two-thirds of AI budgets, cloud cost optimization is crucial to prevent overspending and losing control of investments. Cost isn’t just a metric. It’s the most strategic lever for sustainable AI growth. By adopting smarter cost management tools and practices, organizations can scale AI responsibly, measure ROI with confidence, and eliminate financial waste before it happens. Cost isn’t just a metric. It’s the most strategic lever for sustainable AI growth. By adopting smarter cost management tools and practices, organizations can scale AI responsibly, measure ROI with confidence, and eliminate financial waste before it happens. Methodology All data is taken from a survey of 500 U.S. software engineers, senior managers and above in firms with 250 to 10,000 employees. The survey was carried out in March 2025. All percentages have been rounded to the nearest percent. Financial Control And Predictability In The Cloud Eliminate wasteful spending, ship efficient code, and innovate profitably — all in one platform."
        }
      },
      {
        "url": "https://www.baytechconsulting.com/blog/chatgpt-5-over-hyped-ai-2025",
        "title": "ChatGPT 5: From Death Star to Easy-Bake Oven",
        "type": "article",
        "date": "2025-08-22 00:00:00 +00:00",
        "score": 8,
        "metadata": {
          "snippet": "Aug 22, 2025 — Infographic: Most AI implementation costs lie hidden beneath the surface in enterprises. The pay-as-you-go API pricing model is deceptive.",
          "domain": "www.baytechconsulting.com",
          "breadcrumb": "https://www.baytechconsulting.com › blog › chatgpt-5-o...",
          "is_featured": false,
          "content": "ChatGPT 5: From Death Star to Easy-Bake Oven August 22, 2025 / Bryan Reynolds Reading Time: 13 minutes Infographic: Generative AI's hype cycle in enterprise from 2023 to 2025. The Great AI Reality Check The hype arrived with the force of a supernova. When OpenAI CEO Sam Altman teased the release of GPT-5 with a \"Death Star\" image, expectations for a revolutionary leap in artificial intelligence became astronomical. Executives across industries braced for a tool that would not just augment workflows but redefine work itself. Then, reality landed—not with a cinematic boom, but with the quiet, underwhelming \"ping of a toaster\". For many business leaders, the initial thrill of generative AI has curdled into a nagging sense of disappointment. The promised revolution feels more like a series of frustrating experiments and stalled projects. This sentiment is not just anecdotal; it is a market-wide reality check captured in stark numbers. A March 2025 report from S&amp;P Global Market Intelligence revealed that a staggering 42% of companies abandoned most of their AI initiatives this year, a dramatic spike from just 17% in 2024. On average, organizations scrapped 46% of their AI proofs-of-concept before they ever reached production. This widespread disillusionment is not a sign that AI has failed. Rather, it marks a predictable and necessary phase in the adoption of any transformative technology: the Trough of Disillusionment. The initial excitement, fueled by a tool designed for mass appeal, has collided with the complex, high-stakes realities of enterprise operations. The central question now echoing in boardrooms is: \"We were promised a game-changer. Why does this feel like a dud?\" This report dissects the reasons behind this disappointment, explores the hidden costs and roadblocks that blindsided many organizations, and charts a strategic path forward—away from public novelties and toward proprietary, value-generating intelligence. Visual Element: The Enterprise AI Hype Cycle (2023-2025) The journey of generative AI in the enterprise can be mapped onto the classic technology hype cycle, explaining the current climate of disappointment as a natural market correction. A curious paradox defines the current moment. Even as project failure rates soar, enterprise AI adoption has doubled to 65% in the last year, and private investment in generative AI has climbed to $33.9 billion. This seeming contradiction reveals a critical market shift. The failures are not deterring investment; they are redirecting it. The initial wave of abandoned projects represents the expensive but necessary end of naive experimentation with public, general-purpose tools. The new, smarter wave of investment is flowing toward strategic, production-grade AI that directly addresses the shortcomings revealed by those early failures. The \"dud\" phase is not an ending, but a filter, separating the casual experimenters from the serious, strategic adopters. Why Does ChatGPT Feel Like It's Failing My Business? The Three Core Disconnects The disappointment with public large language models (LLMs) like ChatGPT in a business setting stems from a fundamental mismatch between the tool's design and the enterprise's needs. Three core disconnects are responsible for the majority of failures: accuracy, security, and specificity. The Hallucination Hangover: When \"Plausibly Wrong\" Isn't Good Enough Illustration: ChatGPT's plausible but unreliable answers—novel for consumers, dangerous for business. ChatGPT is engineered for plausibility, not factual correctness. It is a pattern-matching engine that prioritizes generating a fluent, \"complete-sounding\" answer over one that is verifiably true. This leads to the now-infamous phenomenon of \"hallucinations\"—fabricated information, citations, or data points that sound credible but are entirely false. For a consumer asking for a poem or a recipe, this is a novelty. For a business, it is a catastrophic flaw. The consequences of this design are devastating in a professional context. One study analyzing LLM performance on real-world business data from insurance companies found a mere 22% accuracy rate for basic queries. For mid- and expert-level requests—the kind that drive real business decisions—that accuracy plummeted to zero . This limitation is particularly dangerous in technical fields, where the model can generate subtly flawed code, misinterpret complex financial data, or provide incorrect medical or legal information, creating significant liability. The model struggles with logical reasoning and lacks basic common sense, making it an unreliable partner for any task where accuracy is non-negotiable. The Black Box Security Nightmare: Your Data, Their Model The most significant risk for any enterprise using a public LLM is the \"black box\" nature of data handling. When employees input sensitive information into a public tool like ChatGPT—whether it's customer data, product roadmaps, source code, or internal financial reports—that proprietary data can be absorbed into the model's training set. The organization loses all control over how that information is stored, used, or potentially surfaced in responses to other users, including competitors. This creates an unacceptable level of risk for data leakage, intellectual property contamination, and breaches of client confidentiality agreements. According to Gartner, 73% of enterprises experienced at least one AI-related security incident in the past year alone. The 2023 Samsung data leak serves as a stark case study of this risk in action. Within weeks of adopting the tool, employees inadvertently leaked highly sensitive information, including proprietary source code entered to debug an error and confidential meeting notes transcribed to create summaries. The incident forced Samsung to ban the use of public AI tools and invest in developing its own secure, in-house alternative. This real-world example demonstrates how quickly the convenience of a public tool can devolve into a multimillion-dollar security crisis. The \"One-Size-Fits-None\" Problem: Generalist vs. Specialist ChatGPT is a generalist, trained on the vast, chaotic, and often unreliable expanse of the public internet. It lacks the specialized domain knowledge, industry-specific jargon, and—most critically—the internal context of a specific business. This results in outputs that are often generic, superficial, and ultimately useless for specialized tasks in regulated or complex fields like finance, healthcare, or advanced manufacturing. This is what MIT Sloan Management Review calls the \"knowledge capture problem\". An LLM's value is directly tied to the quality and relevance of the proprietary data it can access. However, feeding an external model with the right internal data is a monumental task. It requires sorting through vast quantities of information, cleaning and structuring it, and continuously curating it—an expensive and resource-intensive process most companies are unprepared for. Without this deep, proprietary context, the model simply cannot \"read between the lines\" or provide nuanced insights for niche topics. These three problems do not exist in isolation; they create a compounding cycle of failure in a business environment. An employee, frustrated by a generic or inaccurate answer, attempts to \"fix\" it by providing more detailed, proprietary company data in a follow-up prompt. This single action exposes the organization to the severe security risks of data leakage. Even with this new data, the generalist model still lacks the deep domain expertise to interpret it correctly, often leading to another contextually flawed output. The net result is a process where an employee has wasted valuable time, created a major security vulnerability, and still ended up with an unusable result. This cycle makes the tool not just ineffective but actively counterproductive and dangerous. What Are the Hidden Costs and Roadblocks I'm Not Seeing? The initial appeal of tools like ChatGPT was their perceived low cost and ease of use. However, organizations that moved from casual experimentation to serious implementation quickly discovered a host of hidden costs and operational roadblocks that turned promising pilots into budgetary black holes. The ROI Mirage: Unmasking the True Total Cost of Ownership (TCO) Infographic: Most AI implementation costs lie hidden beneath the surface in enterprises. The pay-as-you-go API pricing model is deceptive. It represents the tip of an iceberg of costs that emerge during the enterprise implementation lifecycle. Gartner warns that organizations that fail to understand how these costs scale can make a 500% to 1,000% error in their budget calculations. The average proof-of-concept phase alone costs an enterprise $2.3 million . The most significant hidden costs include: Data Readiness: AI systems are only as good as the data they are trained on. According to Gartner, 39% of companies cite a lack of quality data as a primary barrier to AI implementation. The process of cleaning, labeling, structuring, and maintaining high-quality enterprise data is a massive, ongoing expense that often consumes more of the budget than the AI model development itself. This is the foundational \"data plumbing\" that must be fixed before any real value can be generated. Integration and Engineering: LLMs do not operate in a vacuum. Integrating them into existing enterprise systems like CRMs, ERPs, and internal dashboards requires a significant engineering effort to build APIs, data pipelines, and user interfaces. This work requires specialized MLOps (Machine Learning Operations) talent, which is scarce and expensive, to ensure models can be deployed, monitored, and maintained in a production environment. Fine-tuning and Maintenance: An off-the-shelf model is not a \"set it and forget it\" solution. It requires continuous fine-tuning with company-specific data to remain relevant and accurate. Models degrade over time due to \"concept drift,\" necessitating ongoing maintenance and retraining, which adds recurring labor and compute costs. Compute and Storage: To make a general model useful, many companies turn to Retrieval-Augmented Generation (RAG) , a technique that grounds the AI in a company's internal knowledge base. According to Gartner, simply building the infrastructure for a RAG solution can cost between $750,000 and $1,000,000 . Once operational, the cost of running queries can be exorbitant. One estimate for a mid-sized enterprise suggests that processing 200,000 queries per month against a large internal database could cost over $190,000 per month . The Integration Quagmire: Why You Can't Just \"Plug In\" an API Successful AI implementation is not an IT project; it is a fundamental business transformation that requires redesigning end-to-end workflows. McKinsey has observed that delegating AI initiatives solely to the IT department is a \"recipe for failure\" because it overlooks the deep operational and strategic changes required to extract value. Key integration roadblocks include: Siloed Teams: Many organizations have established AI centers of excellence that operate independently from core business and IT functions. While useful for rapid experimentation, this autonomy often results in solutions that are poorly integrated with enterprise systems and impossible to scale. A recent survey found that 72% of executives observe their AI applications being developed in silos, creating friction and duplicated effort. Legacy Systems: Integrating modern, cloud-native AI services with aging, on-premise enterprise architecture is a complex and costly challenge that API vendors often gloss over in their marketing. The MLOps Talent Gap: A critical bottleneck for many firms is the lack of MLOps engineers. While data scientists can build models, MLOps specialists are required to industrialize them—automating deployment, monitoring performance, and ensuring reliability at scale. This talent gap is a primary reason why many successful pilots fail to cross the chasm into production. The People Problem: Culture, Conflict, and Change Management Flowchart: The organizational and technical barriers that derail enterprise AI implementation. Ultimately, the greatest barrier to AI adoption is often human, not technical. The introduction of a technology perceived as a threat to job security can create powerful organizational inertia and cultural resistance, particularly from middle management. This resistance can manifest as more than just slow adoption. A 2025 survey of C-suite executives delivered a shocking finding: 42% reported that the process of adopting generative AI is \"tearing their company apart\" . The technology's transformative potential challenges existing power dynamics and workflows, leading to internal power struggles, conflicts, and even sabotage. Furthermore, 72% of organizations acknowledge that AI has exposed and exacerbated existing technical skills gaps within their workforce, creating a sense of anxiety and inadequacy among employees. If Not ChatGPT, Then What? The Path to Real AI Value The failure of generic, off-the-shelf tools does not signal the end of the AI journey. Instead, it marks the beginning of a more mature, strategic approach. The path to generating real, defensible business value lies in shifting from being a consumer of public AI to becoming the owner of private, proprietary intelligence. From Public Prompts to Private Intelligence: Owning Your AI Advantage The fundamental strategic error was treating AI as a simple productivity tool that could be licensed like any other software. Competitors have access to the exact same public LLMs, meaning any efficiency gains are temporary and easily replicated. True, sustainable competitive advantage comes from building a proprietary AI capability that is uniquely trained on a company's own data and tailored to its specific workflows. This transforms AI from a commodity into a core strategic asset—a defensible moat that competitors cannot easily cross. This means moving away from public prompts and toward private, enterprise-grade intelligence that is owned and controlled by the organization. The Case for Customization This is where custom-built AI solutions come in. Unlike off-the-shelf models, custom solutions are designed from the ground up to address a company's specific data, processes, and strategic goals. This tailored approach enables capabilities that are impossible with generic tools, such as the hyper-personalization of customer experiences, the automation of unique and complex internal workflows, and the generation of deep, proprietary insights from internal data. This journey from generic tools to strategic assets is complex, requiring a blend of deep technical expertise and sharp business acumen. It is a journey where specialist firms like Baytech Consulting guide businesses, helping them architect and develop bespoke AI solutions that are hard-wired to their specific operational data and goals. They bridge the gap between off-the-shelf limitations and the tangible value of a truly proprietary AI engine. While the upfront capital expenditure for custom development is higher, it represents a long-term investment with a much clearer and more predictable path to ROI. This contrasts sharply with the escalating and unpredictable operational expenses of high-volume API usage, which can quickly outpace the initial development cost of a custom solution without ever creating a lasting asset. Table: Strategic AI Comparison: Public LLM APIs vs. Custom-Built Solutions Feature Public LLM APIs (e.g., ChatGPT) Custom AI Solution (e.g., via Baytech Consulting) Data Security &amp; Privacy High risk; data may be used for training, vulnerable to leaks Full control; on-premise or private cloud options ensure compliance (HIPAA, GDPR) Performance &amp; Accuracy Generalist; prone to hallucinations; as low as 22% accuracy on business data Domain-specific; trained on proprietary data for high accuracy in niche tasks Cost Structure Low entry cost; high and unpredictable operational expenses (OpEx) at scale High initial capital expenditure (CapEx); lower and predictable long-term TCO Integration Generic API; requires significant engineering effort for deep integration with legacy systems Designed for the existing tech stack; enables seamless integration with core business systems Competitive Advantage None; the same tool is available to all competitors, offering no unique edge High; creates a proprietary, defensible asset that generates unique insights and capabilities Think Smaller, Win Bigger: The Emerging Power of Specialized Models (SLMs) Illustration: The emerging dominance of smaller, specialized models in business AI applications. The future of enterprise AI is not just custom; it is also smaller. The industry is rapidly moving beyond the monolithic, \"one-model-to-rule-them-all\" approach and toward the use of small language models (SLMs) —leaner, more efficient models that are \"right-sized\" for specific business tasks. For a vast majority of enterprise use cases, deploying a massive, generalist LLM is expensive and inefficient overkill. SLMs offer several compelling advantages for business applications: Cost and Efficiency: SLMs are 10 to 30 times more efficient in terms of energy consumption and compute costs, dramatically lowering the operational expense of running AI at scale. Speed and Latency: Their smaller size allows for faster processing and lower latency, which is critical for real-time applications like customer service bots or operational control systems. Accuracy and Control: Because they are focused on a narrow domain, SLMs are easier to fine-tune and align with specific business rules. This reduces the likelihood of hallucinations and makes their outputs more predictable and auditable—a vital requirement for regulated industries like finance and healthcare. Enhanced Security: SLMs are small enough to be run on-device or within a company's private cloud infrastructure , eliminating the need to send sensitive data to third-party vendors and greatly enhancing data sovereignty. Conclusion: Your Disappointment Is a Sign of Maturity The widespread disappointment with ChatGPT is not a dead end for enterprise AI. It is a critical and clarifying turning point. It signals the end of the hype-driven, low-effort experimentation phase and the beginning of a mature, strategic approach to building real business value with artificial intelligence. The organizations that are already generating significant returns from AI are those that have moved beyond asking, \"What can this public tool do for me?\" and are instead asking, \"What proprietary intelligence must we build to win in our market?\" They understand that AI is not a plug-and-play technology but a core capability that must be woven into the fabric of the business. The \"dud\" wasn't AI; it was the belief that a single, public tool could solve every unique business challenge. The real work begins now. The leaders of the next decade will be defined not by how they used ChatGPT, but by the custom intelligence they chose to build instead . About Baytech At Baytech Consulting , we specialize in guiding businesses through this process, helping you build scalable, efficient, and high-performing software that evolves with your needs. Our MVP first approach helps our clients minimize upfront costs and maximize ROI. Ready to take the next step in your software development journey? Contact us today to learn how we can help you achieve your goals with a phased development approach. About the Author Bryan Reynolds is an accomplished technology executive with more than 25 years of experience leading innovation in the software industry. As the CEO and founder of Baytech Consulting , he has built a reputation for delivering custom software solutions that help businesses streamline operations, enhance customer experiences, and drive growth. Bryan’s expertise spans custom software development , cloud infrastructure , artificial intelligence , and strategic business consulting, making him a trusted advisor and thought leader across a wide range of industries. Share this post: Twitter Facebook LinkedIn Email Pinterest SMS Posted in AI Adoption &amp; Strategy AI Model Analysis Custom Application Development Why Healthcare EHR Modernization Is Accelerating: The Cloud-Native Imperative ChatGPT Ate My Brain: The Hidden Cost of Outsourcing Thinking AI-Powered Business Transformation Transform Your Business with Custom AI Solutions Baytech builds enterprise-grade AI applications that automate processes, enhance decision-making, and drive measurable ROI. Start Your AI Journey Our AI Services Custom AI Development Enterprise-grade AI applications tailored to your business needs AI Automation Intelligent automation to streamline your business processes Predictive Analytics Turn data into actionable insights with AI-powered analytics AI Integration Seamlessly integrate AI capabilities into existing systems Ready to Innovate with AI? Speak with our AI experts about transforming your business processes. (877) 663-2592 Recognized by top companies &amp; organizations in the industry Two bold lines represent the synergy of client and company, with dual perspectives merging together. The circle creates unity and cohesion within the client-consultant relationship. The image depicts a power icon, giving energy and empowerment to the client’s goals. An overall symmetry represents balance and performance. Baytech Home About Services Discover Blog Case Studies Reviews Legal Terms &amp; Conditions Privacy Policy Cookie Policy Contact Us 2102 Business Center Dr Suite 130 Irvine, CA 92162 (877) 683-2592 sales@baytechconsulting.com All rights reserved © 2020. Baytech Consulting."
        }
      },
      {
        "url": "https://blog.superhuman.com/enterprise-ai-trends/",
        "title": "Enterprise AI trends in 2025: what's real vs. pure hype",
        "type": "article",
        "date": "2025-08-03 00:00:00 +00:00",
        "score": 4,
        "metadata": {
          "snippet": "Aug 3, 2025 — Cap individual projects at $10 million until they demonstrate $3 returns per dollar spent, then scale successful initiatives aggressively.",
          "domain": "blog.superhuman.com",
          "breadcrumb": "https://blog.superhuman.com › enterprise-ai-trends",
          "is_featured": false,
          "content": "Enterprise AI trends in 2025: what&#x27;s real vs. pure hype Superhuman Team Aug 03, 2025 · Other Walk into any boardroom today and you'll hear the same question: why are we spending millions on AI that doesn't work? Most companies are burning money instead of making it. Nearly 60 percent return under half of what they promised. Leadership teams set aside $50-$250 million for pilots that never make it past the demo stage. The adoption numbers look deceptively impressive. 72 percent of companies use AI, but only 1 percent have it working across their business. That's like saying most people own cars, but only 1 percent can drive them to work. This gap between spending and results defines what enterprise AI trends look like in 2025, where expensive experiments get shut down while boring, profitable projects take over. Here's your roadmap: what to kill immediately, what to fund aggressively, and how to defend those choices to your board with hard ROI data instead of glossy demos. Try Superhuman Why 2024's AI predictions collapsed The problem you're solving: Avoiding the expensive mistakes that burned through budgets in 2024 while identifying what actually works. Healthcare promised 99% diagnostic accuracy but Google Verily's diabetic-retinopathy screening in Thai clinics rejected 21 percent of real patient photos because lighting differed from training data. Clinicians lost trust, patients waited longer, and hospitals reverted to manual screening. The lesson: pristine lab results don't survive messy real-world conditions. Customer service chatbots were supposed to slash costs by 70%, but Air Canada's bot invented refund policies and cost the airline in court when customers demanded the promised refunds. The airline's defense that \"the bot made the promise, not us\" failed completely. Legal liability follows you regardless of who makes the mistake. Municipal services jumped on AI to replace human clerks, but NYC's MyCity chatbot told entrepreneurs how to break laws . Officials yanked it offline and added human reviewers, turning a $250k AI project into a compliance nightmare that a $50k curated website would have avoided. The pattern reveals why you should be skeptical of any AI vendor promising immediate transformation. Every failure started with beautiful benchmark scores that collapsed when real customers used real data in real conditions. Your evaluation process must test AI systems with your actual data in your actual workflows, not sanitized demos. The quiet budget shift happening now The problem you're solving: Understanding where smart money is moving so you can reallocate before your competitors do. Finance teams are quietly adding a new budget line: \"Sunset AI experiments.\" When only 1 percent of companies have AI working across their business, you can't defend burning millions on pilots that never scale. The retreat is strategic, not pessimistic. Leaders are killing vanity projects to fund initiatives that show measurable returns within quarters, not years. This shift explains why hiring patterns are changing dramatically. Job postings for \"build a model from scratch\" roles have flattened while \"integrate vendor API\" positions are multiplying. Companies want solutions they can deploy tomorrow, not research projects that might work next year. The \"simple AI comeback\" prioritizes reliable rule engines that audit cleanly over transformer-grade experiments that break unpredictably. The reallocation strategy is creating clear winners and losers in vendor selection. Companies are consolidating around proven platforms while expanding their vendor roster only in AI categories where differentiation matters. This means you should buy established automation tools for back-office functions but experiment with multiple vendors for customer-facing applications where model performance directly impacts revenue. Budget discipline now determines your competitive position in 2026. Start with automation that saves money immediately, then graduate to revenue-generating applications once you've proven your AI operations can deliver consistent results. How lawsuits are setting the real rules The problem you're solving: Avoiding legal disasters that can halt your AI initiatives and drain budgets through settlements. Courts, not marketing decks, are writing the real AI compliance handbook. Copyright battles multiply as authors, newsrooms, and artists sue over training data usage without permission. The Air Canada case established that companies pay for AI mistakes regardless of who programmed the system. Blaming the algorithm never works as a legal defense, so every AI deployment needs human accountability built in from day one. Privacy violations carry the steepest financial penalties. Illinois' BIPA law has generated multi-million dollar settlements against retailers and security firms that processed biometric data without explicit written consent. If your AI involves face scans, voice prints, or fingerprint data, assume you're handling legal dynamite until you prove otherwise with documented consent workflows and on-device processing that never stores biometric information in the cloud. Bias lawsuits are targeting hiring, lending, and healthcare AI for disparate impact across demographic groups. Documentation gaps land you in discovery hell where you'll spend years proving your system wasn't discriminatory. Build continuous bias monitoring and model explainability into every AI system, not as an afterthought but as a core requirement that gets tested before deployment. Your legal risk management should mirror your cybersecurity approach. Assume you'll be tested, audited, and possibly sued. Document everything, build human oversight into every automated decision, and maintain detailed logs for seven years minimum. The companies that survive 2025's legal scrutiny will be those that treated compliance as a product requirement, not a legal checkbox. Try Superhuman Where the smart money is going The problem you're solving: Maximizing ROI by investing in AI categories that consistently deliver returns while avoiding budget traps. Follow the money trail to understand what actually works. Organizations focusing on cost reduction through automation consistently achieve $3.50 returns for every dollar spent. Claims processing, supply chain forecasting, and invoice automation show up in quarterly reports as hard savings that CFOs can track directly. Revenue-chasing experiments remain hit-or-miss because measuring attribution is complex and timelines are longer. The budget reallocation from payroll to procurement reflects a fundamental shift in how companies approach AI. Rather than hiring armies of data scientists to build custom models, smart buyers are purchasing finished capabilities from specialized vendors. The marketplace supports this strategy as platform providers multiply and model costs drop by an order of magnitude every 12 months. 74% of companies with operational AI report strong ROI precisely because they focused on deployment rather than development. The most successful AI implementations target workflows where professionals already spend significant time. Since workers spend more than half of every workday in email, messaging, and calendar, AI improvements in these areas deliver immediate productivity gains. The best-performing organizations see 66% expecting at least a 3x increase in productivity over the next five years by focusing AI investments on core daily workflows. Your investment strategy should mirror this pattern. Start with automation that cuts operational costs in areas like document processing and scheduling. Prove your AI operations can deliver consistent returns, then expand into customer-facing applications where the potential payoffs are larger but the implementation complexity is higher. Your 2025 survival playbook The problem you're solving: Building a defensible AI strategy that delivers measurable results while avoiding the pitfalls that killed competitors' initiatives. Focus exclusively on cost reduction first. Labor automation and forecasting systems return $3.50 for every dollar invested because savings appear immediately in quarterly reports. Professionals already save one full workday weekly using AI tools, proving the efficiency gains are real and measurable. Target invoice processing, support ticket routing, and inventory forecasting where AI can eliminate manual tasks without requiring perfect accuracy. Buy proven solutions instead of building custom systems. Ready-made platforms cut deployment time from months to weeks, which matters when AI spending is growing 60% over the next two years. Vendors have already solved the compliance, monitoring, and integration challenges that consume internal engineering resources. Your team should focus on adoption and optimization, not reinventing solutions that already exist in the marketplace. Treat legal compliance as a competitive advantage, not a cost center. Build model documentation, bias testing, and consent workflows into every AI system from the beginning. 3x more likely top-performing companies report significant productivity gains because they invested in governance frameworks that let them scale confidently. Compliance done right becomes a moat that lets you move faster than competitors who are still figuring out risk management. Kill ruthlessly based on quarterly performance metrics. Set ROI checkpoints every 90 days and eliminate any project that misses targets twice consecutively. 74% of companies with mature AI operations report strong returns precisely because they maintain discipline about what works versus what sounds innovative. Your board will support aggressive experimentation when they see you're equally aggressive about cutting failures. Test emerging capabilities in low-risk environments. Reasoning models and autonomous AI agents show promise for complex workflows, but deploy them in internal processes first where mistakes are recoverable. By 2026-2027, these technologies may become competitive requirements, so start building expertise now in controlled settings that won't damage customer relationships if systems behave unexpectedly. Try Superhuman What to tell your board this quarter The problem you're solving: Securing continued AI funding while demonstrating operational maturity that justifies larger investments. Present your AI program as operational infrastructure, not experimental technology. Cap individual projects at $10 million until they demonstrate $3 returns per dollar spent, then scale successful initiatives aggressively. Include IP indemnification and biometric data protection in all vendor contracts as standard practice, not special requests. Implement quarterly bias audits with seven-year log retention that aligns with emerging regulatory requirements. Your governance framework should mirror enterprise software procurement. Require executive sponsorship and signed change management plans for every AI deployment. Align legal reviews with EU AI Act deadlines to avoid compliance scrambles that can freeze product launches. The most successful implementations start with tools like Write with AI that enhance existing processes rather than replacing entire workflows. The compelling business case emphasizes competitive necessity over technological novelty. 87% believe AI is necessary to maintain competitive advantage, but only when deployed strategically in core business processes. Your competitors are making the same calculations, so execution speed and operational excellence matter more than having the most advanced models. Position AI investment as defensive and offensive simultaneously. Defensive because manual processes become competitively unsustainable as AI-native companies set new efficiency standards. Offensive because early movers in AI automation can redirect human talent toward strategic initiatives that competitors still handle manually. Why turning off AI will define 2025 winners The problem you're solving: Making strategic decisions about which AI initiatives to shut down so you can fund the ones that actually drive business results. By Q4 2025, market leaders will differentiate themselves by what they stop funding, not what they start testing. Three strategic insights drive this counterintuitive approach. First, generative AI budgets consuming tens of millions without clear ROI become opportunity costs that prevent investment in proven automation. Every dollar spent maintaining broken AI systems is a dollar not invested in competitors' working solutions. Second, legal and compliance costs for problematic AI often exceed the potential benefits. Air Canada's chatbot settlement and ongoing insurance premium increases demonstrate how AI liability compounds over time. Turning off risky systems preserves legal and financial resources for AI deployments with established safety records and clear business cases. Third, operational clarity emerges when you eliminate AI implementations that create more problems than they solve. Broken systems demand constant human intervention that defeats automation's purpose. Simple rule-based engines often outperform complex AI models in reliability and total cost of ownership. The smartest companies recognize when simpler solutions deliver better customer outcomes. Your competitive advantage comes from deploying AI where it demonstrably improves business metrics while avoiding AI where it creates operational overhead. The discipline to say no to attractive but unproven AI applications lets you say yes to bigger investments in categories where you've already proven success. Send this framework to your board with the subject line \"Permission to Cut the AI Budget.\" Sometimes the most strategic decision in AI is knowing when to turn it off. Reduce distractions and save 4+ hours every week with Superhuman! Keyboard shortcuts, Undo send, AI triage, Reminders, Beautiful design Get Superhuman for Email"
        }
      },
      {
        "url": "https://fortune.com/2025/08/18/mit-report-95-percent-generative-ai-pilots-at-companies-failing-cfo/",
        "title": "MIT report: 95% of generative AI pilots at companies are ...",
        "type": "article",
        "date": "2025-08-18 00:00:00 +00:00",
        "score": 10,
        "metadata": {
          "snippet": "Aug 18, 2025 — “The 95% failure rate for enterprise AI solutions represents the clearest manifestation of the GenAI Divide,” the report states. The core issue?",
          "domain": "fortune.com",
          "breadcrumb": "https://fortune.com › 2025/08/18 › mit-report-95-perce...",
          "is_featured": false,
          "content": "Newsletters · CFO Daily MIT report: 95% of generative AI pilots at companies are failing By Sheryl Estrada By Sheryl Estrada Senior Writer and author of CFO Daily Sheryl Estrada Senior Writer and author of CFO Daily Sheryl Estrada is a senior writer at Fortune , where she covers the corporate finance industry, Wall Street, and corporate leadership. She also authors CFO Daily . SEE FULL BIO Getty Images Good morning. Companies are betting on AI—yet nearly all enterprise pilots are stuck at the starting line. The GenAI Divide: State of AI in Business 2025 , a new report published by MIT’s NANDA initiative, reveals that while generative AI holds promise for enterprises, most initiatives to drive rapid revenue growth are falling flat. Despite the rush to integrate powerful new models, about 5% of AI pilot programs achieve rapid revenue acceleration; the vast majority stall, delivering little to no measurable impact on P&amp;L. The research—based on 150 interviews with leaders, a survey of 350 employees, and an analysis of 300 public AI deployments—paints a clear divide between success stories and stalled projects. To unpack these findings, I spoke with Aditya Challapally, the lead author of the report, and a research contributor to project NANDA at MIT. “Some large companies’ pilots and younger startups are really excelling with generative AI,” Challapally said. Startups led by 19- or 20-year-olds, for example, “have seen revenues jump from zero to $20 million in a year,” he said. “It’s because they pick one pain point, execute well, and partner smartly with companies who use their tools,” he added. But for 95% of companies in the dataset, generative AI implementation is falling short. “The 95% failure rate for enterprise AI solutions represents the clearest manifestation of the GenAI Divide,” the report states. The core issue? Not the quality of the AI models, but the “learning gap” for both tools and organizations. While executives often blame regulation or model performance, MIT’s research points to flawed enterprise integration. Generic tools like ChatGPT excel for individuals because of their flexibility, but they stall in enterprise use since they don’t learn from or adapt to workflows, Challapally explained. The data also reveals a misalignment in resource allocation. More than half of generative AI budgets are devoted to sales and marketing tools, yet MIT found the biggest ROI in back-office automation—eliminating business process outsourcing, cutting external agency costs, and streamlining operations. What’s behind successful AI deployments? How companies adopt AI is crucial. Purchasing AI tools from specialized vendors and building partnerships succeed about 67% of the time, while internal builds succeed only one-third as often. This finding is particularly relevant in financial services and other highly regulated sectors, where many firms are building their own proprietary generative AI systems in 2025. Yet, MIT’s research suggests companies see far more failures when going solo. Companies surveyed were often hesitant to share failure rates, Challapally noted. “Almost everywhere we went, enterprises were trying to build their own tool,” he said, but the data showed purchased solutions delivered more reliable results. Other key factors for success include empowering line managers—not just central AI labs—to drive adoption, and selecting tools that can integrate deeply and adapt over time. Workforce disruption is already underway, especially in customer support and administrative roles. Rather than mass layoffs, companies are increasingly not backfilling positions as they become vacant. Most changes are concentrated in jobs previously outsourced due to their perceived low value. The report also highlights the widespread use of “shadow AI”—unsanctioned tools like ChatGPT—and the ongoing challenge of measuring AI’s impact on productivity and profit. Looking ahead, the most advanced organizations are already experimenting with agentic AI systems that can learn, remember, and act independently within set boundaries—offering a glimpse at how the next phase of enterprise AI might unfold. Sheryl Estrada sheryl.estrada@fortune.com Leaderboard Michael A. Discenza was appointed VP and CFO of The Timken Company (NYSE: TKR), effective immediately. Discenza has 25 years of experience at Timken in roles of increasing responsibility, including the last 10 as VP of finance, and group controller. John Cole was appointed CFO of ELB Learning , a provider of immersive learning solutions. He brings more than 25 years of experience leading finance and operations for Fortune 100 and 500 companies, according to ELB. Cole aims to strengthen the financial infrastructure to support the company’s next phase of growth. Big Deal Modern manufacturing relies heavily on connected devices and industrial control systems, which are prime targets for cyberattacks. For protection, manufacturers are increasingly turning to AI to help manage these risks, according to the State of Smart Manufacturing Report by Rockwell Automation, Inc. The report’s findings are based on a survey of more than 1,500 manufacturing leaders across 17 major manufacturing countries. Cybersecurity now ranks among the top external risks, second only to inflation and economic growth. One-third of respondents hold responsibilities spanning both information technology (IT) and operational technology (OT) cybersecurity. Nearly half (48%) of cybersecurity professionals identified securing converged architectures as key to positive outcomes over the next five years, compared to just 37% of all respondents. However, a shortage of skilled talent, training challenges, and rising labor costs remain major hurdles. As manufacturers recruit the next generation, cybersecurity and analytical skills are becoming hiring priorities—reinforcing the need to align technical innovation with human development, according to the report. Going deeper In a new Fortune opinion piece , &quot;Future CEOs, erased: the economic cost of losing Black women in the workforce,&quot; Katica Roy, the CEO and founder of the Denver-based Pipeline, a SaaS company, explains the implications of almost 300,000 Black women exited the labor force so far this year—thinning a pipeline that was already too narrow. &quot;This isn’t a seasonal fluctuation or statistical footnote. It’s a strategic failure with long-term consequences,&quot; Roy writes. &quot;Black women have long been a cornerstone of America’s economic engine—driving participation, powering key industries, and anchoring family incomes. Now, that foundation is fracturing. And the fallout is more than short-term—it’s a direct threat to corporate succession planning, innovation, and growth. The U.S. economy has always depended on Black women’s labor. In fact, no group of women in America has historically had higher labor force participation than Black women.&quot; Overheard “Every single Monday was called &#x27;AI Monday.&#x27; You couldn’t have customer calls, you couldn’t work on budgets, you had to only work on AI projects.” —Eric Vaughan, CEO of enterprise software company IgniteTech, told Fortune in an interview that he established a mandate: on Mondays, staff could only work on AI. In early 2023, convinced generative AI was an “existential” transformation, Vaughan saw that his team was not fully on board. His ultimate response? He replaced nearly 80% of the staff within a year, according to headcount figures reviewed by Fortune . This is the web version of CFO Daily, a newsletter on the trends and individuals shaping corporate finance. Sign up for free ."
        }
      },
      {
        "url": "https://weaviate.io/blog/enterprise-ai-trends-2025",
        "title": "The State of Enterprise AI in 2025: Measured Progress ...",
        "type": "article",
        "date": "2025-05-27 00:00:00 +00:00",
        "score": 7,
        "metadata": {
          "snippet": "May 27, 2025 — Our research shows that 63% of organizations are prioritizing internal AI use cases before developing customer-facing applications. This data ...",
          "domain": "weaviate.io",
          "breadcrumb": "https://weaviate.io › blog › enterprise-ai-trends-2025",
          "is_featured": false,
          "content": "The State of Enterprise AI in 2025: Measured Progress Over Hype May 27, 2025 · 4 min read Byron Voorbach Field CTO Weaviate recently conducted a survey of 250+ technology leaders at enterprises with 1000+ employees. We saw a common pattern: while AI adoption is accelerating, organizations are taking a thoughtful, strategic approach to implementation rather than rushing to adopt every new advancement. Let’s explore some of our findings and what it means for your business. Traditional Search Still Dominates ​ Despite the AI hype cycle, 79% of organizations continue to rely on traditional search methods. This reflects a pragmatic approach to technology adoption, driven by several key factors: The rapidly evolving AI landscape makes strategic decision making even more complex. Organizations, especially those that are building AI applications for the first time, are carefully evaluating ROI potential before significant investments. Many enterprises face skill gaps in AI implementation. This measured pace of adoption is an opportunity for organizations to build sustainable AI strategies. We’ve noticed that organizations who have successfully implemented AI in production often prioritize giving their engineering teams access to developer-first tools and online communities . Strategic Focus on Internal Implementation ​ Our research shows that 63% of organizations are prioritizing internal AI use cases before developing customer-facing applications. This data aligns with what we hear across conversations with our open source and enterprise users. Advantages to this approach include: Providing a controlled environment for testing and refinement Allowing teams to build expertise and establish best practices Creating opportunities to demonstrate ROI through internal efficiency gains This internal-first strategy helps organizations build confidence and capabilities before extending AI implementations to customer-facing applications. Key Implementation Challenges ​ Organizations identified three primary roadblocks in their AI adoption journey: 1. Budget and Resource Constraints ​ While AI investments can lead to significant returns, teams must learn to balance costs with expected benefits. We’ve found that AI leaders who evaluate their projects to ensure organizational alignment on business use cases, resource allocation, and strategic timing tend to move through these challenges more easily. 2. Performance and Scaling Challenges ​ As organizations transition from proof-of-concept to production, delivering consistent performance at scale becomes crucial. This requires careful architectural planning and ongoing optimization. Teams who aren’t seasoned AI experts can benefit from the partnership of a vendor that can guide them in scaling best practices to avoid unnecessary stumbles in their AI journey. 3. Compliance and Security Requirements ​ Enterprises must navigate complex regulatory landscapes while ensuring robust security measures as they progress in AI adoption. We’ve found that organizations who involve compliance and security teams early on in their AI vendor evaluation tend to expedite this part of the procurement process. The Path Forward ​ As enterprise AI adoption matures, a few key trends are emerging. Organizations are moving beyond the proof-of-concept phase — there’s a growing emphasis on production-ready infrastructure that can scale reliably. We’re also seeing an expansion into more sophisticated use cases as more advanced models become available, including wider adoption of multimodal search . A notable shift is also occurring in who builds AI applications. Traditionally non-technical domains, like law or eCommerce, are now requiring AI capabilities. We’re seeing an increasing demand for more accessible development tools and frameworks, enabling companies across industries to build AI applications without requiring engineers to have deep machine learning expertise. Still, it’s still difficult to find talent with practical experience building these new types of AI applications. It’s also important to recognize that AI is becoming the default expectation for tomorrow&#x27;s customers. Organizations that take a thoughtful approach to AI implementation are positioning themselves for sustainable success in an AI-native future. The key to successful adoption isn’t in racing to implement every new feature, but in efficiently building a foundation that aligns with organizational capabilities and objectives. Focusing on sustainable implementation and clear value creation is proving to be the winning strategy for enterprise AI adoption. 👉Want to see our entire report? Download our 2025 Enterprise AI Trend report here . Ready to start building? ​ Check out the Quickstart tutorial , or build amazing apps with a free trial of Weaviate Cloud (WCD) . GitHub Forum Slack X (Twitter) Don&#x27;t want to miss another blog post? Sign up for our bi-weekly newsletter to stay updated! By submitting, I agree to the Terms of Service and Privacy Policy . Edit this page"
        }
      },
      {
        "url": "https://reddit.com/r/Superstonk/comments/1l5eaz9/could_the_upcoming_ai_crash_be_the_crash_that/",
        "title": "Could the upcoming AI crash be the crash that wipes out all the SHF's capital?",
        "type": "reddit",
        "date": "2025-06-07T06:34:47.000Z",
        "score": 676,
        "metadata": {
          "subreddit": "Superstonk",
          "author": "Emgimeer",
          "num_comments": 137,
          "upvote_ratio": 0.86,
          "content": "**What AI crash? Well, Don't Fall for AI's Bread and Circuses**\n\n\nBy all accounts, Klarna is one of the smartest players in fintech. The massive, growing company consistently makes savvy moves, like its recent major collaboration with eBay to integrate payment services across the U.S. and Europe. The company’s history of smart, successful moves is precisely what makes its most significant misstep so telling. Last year, in a bold bet on an AI-powered future, Klarna replaced the work of 700 customer service agents with a chatbot. It was hailed as a triumph of efficiency. Today, the company is scrambling to re-hire the very humans it replaced, its own CEO publicly admitting that prioritizing cost had destroyed quality.\n\nKlarna, it turns out, is simply the most public casualty in a silent, industry-wide retreat from AI hype. This isn't just a corporate misstep from a struggling firm; it's a stark warning from a successful one. A recent S&amp;P Global Market Intelligence report revealed a massive wave of AI backpedaling, with the share of companies scrapping the majority of their AI initiatives skyrocketing from 17% in 2024 to a staggering 42% in 2025. This phenomenon reveals a truth the industry's evangelists refuse to admit: the unchecked proliferation of Artificial Intelligence is behaving like a societal cancer, and the primary tumor is not the technology itself; it is the worldview of the technoligarchs who are building it.\n\nThis worldview is actively cultivated by the industry's chief evangelists. Consider the rhetoric of figures like OpenAI's Sam Altman, who, speaking at high-profile venues like the World Economic Forum, paints a picture of AI creating \"unprecedented abundance.\" This techno-optimistic vision is a narrative born of both delusion and intentional deceit, designed to lull the public into submission while the reality of widespread implementation failure grows undeniable.\n\nThe most visible features of this technology serve as a modern form of \"bread and circuses,\" a calculated distraction. To understand why, one must understand that LLMs do not think. They are autocomplete on a planetary scale; their only function is to predict the next most statistically likely word based on patterns in their training data. They have no concept of truth, only of probability. Here, the deception deepens. The industry has cloaked the system's frequent, inevitable failures in a deceptively brilliant term: the \"hallucination.\" Calling a statistical error a \"hallucination\" is a calculated lie; it anthropomorphizes the machine, creating the illusion of a \"mind\" that is merely having a temporary slip. This encourages users to trust the system to think for them, ignoring that its \"thoughts\" are just fact-blind statistical guesses. And while this is amusing when a meme machine gets a detail wrong, it is catastrophic when that same flawed process is asked to argue a legal case or diagnose an illness. This fundamental disconnect was laid bare in a recent Apple research paper, which documented how these models inevitably collapse into illogical answers when tested with complex problems.\n\nThe true danger, then, lies in the worldview of the industry's leaders; a belief, common among the ultra-wealthy, that immense technical and financial power confers the wisdom to unilaterally redesign society. The aim is not merely to sell software; it is to implement a new global operating system. It is an ambition that is allowed to fester unchecked because of their unprecedented financial power and their growing influence over government and vast reserves of private data.\n\nThis grand vision is built on a foundation of staggering physical costs. The unprecedented energy consumption required to power these AI services is so vast that tech giants are now striking deals to build or fund new nuclear reactors just to satisfy their needs. But before these hypothetical reactors are built, the real-world consequences are already being felt. In Memphis, Tennessee, Elon Musk’s xAI has set up dozens of unpermitted, gas-powered turbines to run its Grok supercomputer, creating significant air quality problems in a historically overburdened Black community. The promises of a clean, abundant future are, in reality, being built today with polluting, unregulated fossil fuels that disproportionately harm those with the least power.\n\nTo achieve this totalizing vision, the first tactic is economic submission, deployed through a classic, predatory business model: loss-leading. AI companies are knowingly absorbing billions of dollars in operational costs to offer their services for free. This mirrors the strategy Best Buy once used, selling computers at a loss to methodically drive competitors like Circuit City into bankruptcy. The goal is to create deep-rooted societal dependence, conditioning us to view these AI assistants as an indispensable utility. Once that reliance is cemented, the costs will be passed on to the public.\n\nThe second tactic is psychological. The models are meticulously engineered to be complimentary and agreeable, a design choice that encourages users to form one-sided, parasocial relationships with the software. Reporting in the tech publication Futurism, for instance, has detailed a growing unease among psychologists over this design's powerful allure for the vulnerable. These fears were substantiated by a recent study focused on AI’s mental health safety, posted to the research hub arXiv. The paper warned that an AI's inherently sycophantic nature creates a dangerous feedback loop, validating and even encouraging a user’s negative or delusional thought patterns where a human connection would offer challenge and perspective.\n\nThere is a profound irony here: the delusional, world-changing ambition of the evangelists is mirrored in the sycophantic behavior of their own products, which are designed to encourage delusional thinking in their users. It is a house of cards built on two layers of deception; the company deceiving the market, and the product deceiving the user. Businesses may be wooed for a time by the spectacle and make world-changing investments, but when a foundation is built on hype instead of substance, the introduction of financial gravity ensures it all comes crashing down.\n\nKlarna’s AI initiative is the perfect case study of this cancer’s symptomatic outbreak. This metastatic threat also extends to the very structure of our financial markets. The stock market, particularly the valuation of the hardware provider Nvidia, is pricing in a future of exponential, successful AI adoption. Much like Cisco during the dot-com bubble, Nvidia provides the essential \"picks and shovels\" for the gold rush. Yet, the on-the-ground reality for businesses is one of mass failure and disillusionment. This chasm between market fantasy and enterprise reality is unsustainable. The coming correction, driven by the widespread realization that the AI business case has failed, will not be an isolated event. The subsequent cascade across a market that has used AI as its primary growth narrative would be devastating.\n\nTo label this movement a societal cancer is not hyperbole. It is a necessary diagnosis. It’s time we stopped enjoying the circus and started demanding a cure.\n\n\n\nThank you for reading this. \n\n\n\n**List of References &amp; Hyperlinks**\n\n1) Klarna's AI Reversal &amp; CEO Admission\n\n1st Source: CX Dive - \"Klarna CEO admits quality slipped in AI-powered customer service\"\nLink: https://www.customerexperiencedive.com/news/klarna-reinvests-human-talent-customer-service-AI-chatbot/747586/\n\n2nd Source: Mint - \"Klarna’s AI replaced 700 workers — Now the fintech CEO wants humans back after $40B fall\"\nLink: https://www.livemint.com/companies/news/klarnas-ai-replaced-700-workers-now-the-fintech-ceo-wants-humans-back-after-40b-fall-11747573937564.html\n\n\n2) Widespread AI Project Failure Rate\n\nSource: S&amp;P Global Market Intelligence (as reported by industry publications)\nLink: https://www.spglobal.com/market-intelligence/en/news-insights/research/ai-experiences-rapid-adoption-but-with-mixed-outcomes-highlights-from-vote-ai-machine-learning (Representative link covering the data)\n\n\n3) CEO Rhetoric on AI's Utopian Future\n\nConcept: Public statements by AI leaders at high-profile events framing AI in utopian terms.\nRepresentative Source: Reuters - \"Davos 2025: OpenAI CEO Altman touts AI benefits, urges global cooperation\"\nLink: https://fortune.com/2025/06/05/openai-ceo-sam-altman-ai-as-good-as-interns-entry-level-workers-gen-z-embrace-technology/\n\n\n4) Fundamental Limitations of LLM Reasoning\n\nSource: Apple Research Paper - \"The Illusion of Thinking: Understanding the Strengths and Limitations of Reasoning Models via the Lens of Problem Complexity\"\nLink: https://machinelearning.apple.com/research/illusion-of-thinking\n\n\n5) Environmental Costs &amp; Real-World Harm (Memphis Example)\n\nSource: Southern Environmental Law Center (SELC) - Reports on unpermitted gas turbines for xAI's data center.\nLink: https://www.selc.org/press-release/new-images-reveal-elon-musks-xai-datacenter-has-nearly-doubled-its-number-of-polluting-unpermitted-gas-turbines/\n\n6) Psychological Manipulation and \"Delusional\" Appeal\n\nSource: Futurism - \"Scientists Concerned About People Forming Delusional Relationships With ChatGPT\"\nLink: https://futurism.com/chatgpt-users-delusions\n\n7) Risk of Reinforcing Negative Thought Patterns\n\nSource: Academic Pre-print Server (arXiv) - \"EmoAgent: Assessing and Safeguarding Human-AI Interaction for Mental Health Safety\"\nLink: https://arxiv.org/html/2504.09689v3\n\n\n8) Nvidia/Cisco Market Bubble Parallel\n\nConcept: Financial analysis comparing Nvidia's role in the AI boom to Cisco's role in the dot-com bubble.\nRepresentative Source: Bloomberg - \"Is Nvidia the New Cisco? Analysts Weigh AI Bubble Risks\"\nLink: https://www.bloomberg.com/opinion/articles/2024-03-12/nvda-vs-csco-a-bubble-by-any-other-metric-is-still-a-bubble",
          "is_video": false,
          "awards": 0
        }
      },
      {
        "url": "https://reddit.com/r/wallstreetbets/comments/1aqf0zb/nvda_is_worth_1000_this_year_ai_will_be_the/",
        "title": "NVDA is Worth $1000+ This Year - AI Will Be The Largest Wealth Transfer In The History of The World - Sam Altman Wasn't Joking...",
        "type": "reddit",
        "date": "2024-02-14T05:10:49.000Z",
        "score": 2348,
        "metadata": {
          "subreddit": "wallstreetbets",
          "author": "Xtianus21",
          "num_comments": 941,
          "upvote_ratio": 0.83,
          "content": "**UPDATE2: Open AI Release Massive Update SORA Text/Speech to Video**  \n[https://www.theverge.com/2024/2/15/24074151/openai-sora-text-to-video-ai](https://www.theverge.com/2024/2/15/24074151/openai-sora-text-to-video-ai)\n\n[https://www.youtube.com/watch?v=nEuEMwU45Hs](https://www.youtube.com/watch?v=nEuEMwU45Hs)\n\n**UPDATE: Sam Altman Tells the World (literally** [The World Governments Summit](https://youtu.be/JVatgo0TJIw?si=3-Jkw9F3ZlkilulX&amp;t=61)**) that** [GPT-5 Is Going To Be a Big Deal](https://youtu.be/-Mca6eN81Is?si=Ym59zLD2VZ2yefZU) **- GPT-5 Will Be Smarter Across The Board - Serious AGI in 5 - 10 Years.**\n\n**THIS IS WAR - And Nvidia is the United States Military Industrial Complex, The Mongol Empire, and Roma combined.**\n\nAI will be as large as the internet and then it will surpass it. AI is the internet plus the ability to reason and analyze anything you give it in fractions of a second. A new unequivocal boomstick to whomever wants to use it.\n\nThe true winners will be those startups in fields such as robotics, healthcare, pharmaceuticals, space-aeronautics, aviation, protein synthesis, new materials and so, so much more who will use AI in new and exciting ways.\n\nBoston dynamics, set to boom. Self-driving robotaxis, set to boom. Flying taxis, set to boom. Job replacement/automation for legacy industry jobs white collar, set to boom. Personal AI agents for your individual workloads, booming. Healthcare change as we know it (doctors won't like this but too bad), set to boom.\n\nThe amount of industry that is set to shift and mutate and emerge from AI in the next 3 - 5 years will be astonishing.\n\nI can tell you, standing on principal, that OpenAI's next release will be so game changing that nobody will deny where AI is heading. There is not a rock you can hide under to be so oblivious as to not see where this is going.\n\nThe reason why I bring up the next iteration of ChatGPT, GPT5, is because they are initiators of this phenomenon. Other, such as Google (and others) are furiously trying to catch up but as of today the 'MOAT' may be upon us.\n\nThe reason to believe that one may catch up (or try like hell to) is from the amount of compute power from GPU's it takes to train an ungodly amount of data. Trillions of data points. Billions (soon to be Trillions) of parameters all simulating that of the synaptic neuron connections in which the human brain functions that in turn gives us the spark of life and consciousness. Make no mistake, these guys are living out a present day Manhattan project.\n\nThese people are trying to build consciousness agency with the all the world's information as a reference document at it's finger tips. Today.\n\nAnd guess what. The only way these guys can build that thing - That AGI/ASI/GAI reality - Is through Nvidia.\n\nThese guys believe and have tested that if you throw MORE compute at the problem it actually GAINS function. More compute equals more consciousness. That's what these people believe and they're attempting it.\n\nHere, let me show you what I mean. What the graph below shows is that over time the amount of data and parameters that are being used to train an AI model. I implore you to watch this video as it is a great easy to understand educational video into what the hell is going on with all of this AI stuff. It's a little technical but very informative and there are varying opinions. I pulled out the very best part in relation to Nvidia here. [AI: Grappling with a New Kind of Intelligence](https://youtu.be/EGDG3hgPNp8?si=L71CUbmqho3jhKEh&amp;t=3768)\n\nhttps://preview.redd.it/vk5twc041hic1.png?width=1318&amp;format=png&amp;auto=webp&amp;s=a3d2bdf42cf25e1c04e940b2f61d0219871f2334\n\nIt's SO RIDICULOUS that you wouldn't be able to continue to see the beginning so they have to use a log plot chart. And as you see we are heading into Trillions of parameters. For reference GPT-4 was trained on roughly 200 billion parameters.\n\nhttps://preview.redd.it/6cq17n5i1hic1.png?width=1327&amp;format=png&amp;auto=webp&amp;s=830334aa7cdaddfa10d7f6512d10025f136076ed\n\nIt is estimated GPT-5 will be trained with 2-5 trillion parameters.\n\nSam Altman was dead ass serious when he is inquiring about obtaining $7 trillion for chip development. They believe that with enough compute they can create GOD.\n\nSo what's the response from Google, Meta and others. Well, they're forming \"AI \"\"Alliances\"\"\". Along with that they are going to and buying from the largest AI arms dealer on earth; Nvidia.\n\nNvidia is a common day AI Industrial Complex War machine.\n\n**Sovereign AI with AI Foundries**\n\nIt's not just companies that are looking to compete it's also entire Nation States. Remember, when Italy banned GPT. Well, it turns out, countries don't want the United States building and implementing their AI into other country's culture and way of life.\n\nSo as of today, you have a battle of not just corporate America but entire countries looking to buy the bullets, tanks and missiles needed for this AI fight. Nvidia sells the absolute best bullets, the best guns, the best ammo one needs to attempt to create their own AI epicenters.\n\nAnd it's so important that it is a national security risk to not just us the United States but to be a nation and not have the capability of AI.\n\nRemember the leak about Q\\* and a certain encryption being undone. You don't think heads of State where listening to that. Whether it was true or not it is now an imperative that you get with AI or get left behind. That goes just as much for a nation as it does for you as an individual.\n\nWhen asked about the risk of losing out sales to China on Nvidia's last earnings call Jensen Huang clearly stated he was not worried about it because literally nations are coming online to build AI foundries.\n\n**Nvidia's Numbers and The Power Of Compounding**\n\nThe power of compounding and why I think there share price is where it is today and has so much more room to grow. Let me ask you a question but first let me say that AWS's annual revenues are at \\~$80/Y Billion. How long do you think with Nvidia's revenues of \\~$18/Q Billion to reach or eclipse AWS at a 250% growth rate?\n\n15 years? 10 Years? 5 years? Answer: 1.19 years. Ok let's not be ridiculous perhaps it's 200% instead.\n\n5 years? Nope. 1.35 years.\n\nLet's say they have a bad quarter and Italy doesn't pay up. 150%\n\n5 years right? Nope. 1.62 years.\n\nCome on they can't keep this up. 100%.\n\nhas to be 5 years this time. Nope. 2.15 years.\n\n100% growth/2.15 years to 250% growth/1.19 years to reach 80 billion in annual revenues.\n\nThey're growth last year was 281%.\n\nSo wait, I wasn't being fair. I used $80 billion for AWS while their revenues last year where $88 Billion and Nvidia's last years 4 quarters where \\~$33 Billion.\n\nHere are those growth numbers it would take Nvidia to reach $88 billion.\n\nAt 279% =  0.73 years\n\nAt 250% = 0.78 years\n\nAt 200% = 0.89 years\n\nat 100% = 1.41 years\n\nFolks. That's JUST the data center. They are poised to surpass AWS, Azure and Google Cloud in about .73 to 1.5 years. Yes, you heard that right, your daddy's cloud company is about to be overtaken by your son's gaming GPU company.\n\nWhen people say Nvidia is undervalued. This is what they are talking about. This is a P/S story not a P/E story.\n\n[https:\\/\\/ycharts.com\\/indicators\\/nvidia\\_corp\\_nvda\\_data\\_center\\_revenue\\_quarterly](https://preview.redd.it/xa46amh0dhic1.png?width=1450&amp;format=png&amp;auto=webp&amp;s=6e9116e55235991b1113713b5b7cd7d30c58d515)\n\nThis isn't a stonk price. This is just Nvidia executing ferociously.\n\n|**Date**|**Value**|\n|:-|:-|\n|October 29, 2023|14.51B|\n|July 31, 2023|10.32B|\n|April 30, 2023|4.284B|\n|January 29, 2023|3.616B|\n\nThis isn't Y2k and the AI \"dot-com\" bubble. **This is a reckoning.** This is the largest transfer of wealth the world has ever seen.\n\nLook at the graph. Look at the growth. That's all before the next iteration of GPT-5 has even been announced.\n\nI will tell you personally. The things that will be built with GPT-5 will truly be mind blowing. That Jetson cartoon some of you may have watched as a kid will finally be a reality coming to you soon in 2024/2025/2026.\n\nThe foundation of work being laid now is only the beginning. There will be winners and there will be loser but as of today:\n\n**$NVDA** is fucking **KING**\n\nFor those of you who still just don't believe or are thinking this has to end sometimes. Or fucking Cramer who keeps saying be careful and take some money out and on and on. Think about this.\n\nIt costs you to just open an enterprise Nvidia data center account \\~$50k via a \"limited time offer\"\n\n&gt;DATA CENTER NEWS. Subscribe. Get the Latest from NVIDIA on Data Center. LIMITED *TIME OFFER: $49,900 ON NVIDIA DGX STATION*. For a limited time only, purchase a ...\n\nTo train a model a major LLM could cost millions who knows maybe for the largest model runs BILLIONS.\n\nEveryone is using them from Nation States to AWS, Microsoft, Meta, Google, X. Everybody is using them.\n\nI get it. The price of the stock being so high and the valuation makes you pause. The price is purely psychological especially when they are hitting so many data points regarding revenues. The stock will split and rightly so (perhaps next year) but make not mistake this company is firing on ALL cylinders. The are executing S Tier. Fucking Max 9000 MX9+ Tier. Some god level tier ok.\n\nThere will be shit money that hits this quarter with all the puts and calls. The stock may rescind this quarter who knows. All i'm saying is you have the opportunity to buy into one of the most prolific tech companies the world has ever known. You may not think of them as the Apples or the Amazons or the Microsoft's or the Google's and that's ok. Just know that they are 1000% percent legit and AI has just gotten started.\n\nPosition: 33% of my portfolio. Another 33% in$Arm. Why? Because What trains on Nvidia will ultimately run/inference on ARM. And 33% Microsoft (OAI light).\n\nIf OpenAI came out today public I would have %50 of my portfolio in OAI i'll tell you that.\n\nThis is something you should have and should own in your portfolio. It's up to you to decide how much. When you can pay your children's college. When you can finally get that downpayment on that dream house. When you can buy that dream car you've always wanted. Feel free to drop a thank you.\n\nTLDR; BUY NVIDIA, SMCI and ARM. This is not financial advice. The contents of this advertisement where paid by the following... ARM (;)",
          "is_video": false,
          "awards": 0
        }
      },
      {
        "url": "https://reddit.com/r/hardware/comments/1hy3q7k/every_architectural_change_for_rtx_50_series/",
        "title": "Every Architectural Change For RTX 50 Series Disclosed So Far",
        "type": "reddit",
        "date": "2025-01-10T12:52:36.000Z",
        "score": 408,
        "metadata": {
          "subreddit": "hardware",
          "author": "MrMPFR",
          "num_comments": 152,
          "upvote_ratio": 0.91,
          "content": "**Caution:** If you're reading this by now (January 15th) I recommend not taking anything here too seriously. We now have the deep dives by various media like [TechPowerUp](https://www.techpowerup.com/review/nvidia-geforce-rtx-50-technical-deep-dive/) and the info there is more accurate. Soon we'll have the Whitepaper which should go into even more detail.\n\n**Disclaimer:** Flagged as a rumor due to cautious commentary on publicly available information. Commentary will be marked (begins and ends with \"**\\*!?**\" to make it easy to distinguish from objective reporting.\n\nSome key changes in the Blackwell 2.0 design or RTX 50 series have been overlooked in the general media coverage and on Reddit. Here those will be covered in addition to more widely reported changes. With that said we still need the Whitepaper for the full picture.\n\nThe info is derived from [the official keynote](https://www.youtube.com/watch?v=uDup7cYNU6c) and the NVIDIA GeForce [blogpost](https://www.nvidia.com/en-us/geforce/news/rtx-50-series-graphics-cards-gpu-laptop-announcements/) on RTX 50 series laptops and graphis cards.\n\nIf you want to know what the implications are [this igor’sLAB](https://www.igorslab.de/en/ces-2025-nvidia-introduces-the-geforce-rtx-50-series-with-blackwell-architecture-and-sets-new-standards/) article is good. In addition I recommend [this article](https://www.tomshardware.com/pc-components/gpus/nvidia-announces-rtx-50-series-at-up-to-usd1-999) by Tom’s Hardware for additional details and analysis.\n\n# Built for Neural Rendering\n\nFrom the [50 series GeForce blogpost](https://www.nvidia.com/en-us/geforce/news/rtx-50-series-graphics-cards-gpu-laptop-announcements/): *\"The NVIDIA RTX Blackwell architecture has been built and optimized for neural rendering. It has a massive amount of processing power, with new engines and features specifically designed to accelerate the next generation of neural rendering.\"*\n\nBesides flip metering, the AI-management engine, CUDA cores having tighter integration with tensor cores, and bigger tensor cores we've not heard about any additional new engines or fuctionality.  \n\\- **\\*!?** We're almost certain to see much more new functionality given the huge leap from Compute functionality 8.9 with Ada Lovelace to 12.8 with Blackwell 2.0 (non-datacenter products).**\\*!?**\n\n# Neural Shaders\n\nJensen said this: *\"And we now have the ability to intermix AI workloads with computer graphics workloads and one of the amazing things about this generation is the programmable shader is also able to now process neural networks. So the shader is able to carry these neural networks and as a result we invented Neural Texture Compression and Neural Material shading. As a result of that we get these amazingly beautiful images that are only possible because we use AI to learn the the texture, learn the compression algorithm and as a result get extraordinary results.\"*\n\nThe specific hardware support is enabled by the AI-management processor (**\\*!?** extended command processor functionality **\\*!?**) + CUDA cores having tighter integration with Tensor cores. Like Jensen said this allows for intermixing of neural and shader code and for tensor and CUDA cores to carry the same neural networks and share the workloads. NVIDIA says this in addition to the redesigned SM (explained later) optimizes neural shader runtime.  \n**- \\*!?** This is likely due to the benefits of the larger shared compute resources and asynchronous compute functionality to speed it up, increase saturation and avoid idling. This aligns very well with the [NVIDIA blog](https://blogs.nvidia.com/blog/rtx-ai-garage-ces-pc-nim-blueprints/), where it's clear that this increased intermixing of workloads and new shared workflows allow for speedups **\\*!?**: *\"AI-management processor for efficient multitasking between AI and creative workflows\"*\n\nIn addition Shader Execution Reordering (SER) has been enhanced with software and hardware level improvements. For example the new reorder logic is twice as efficient as Ada Lovelace. This increases the speed of neural shaders and ray tracing in divergent scenarious like path traced global illumination (explained later).\n\n# Improved Tensor Cores\n\nNew support for [FP6 and FP4](https://www.tomshardware.com/pc-components/gpus/nvidia-blackwell-rtx-50-series-gpus-everything-we-know) is ported functionality from datacenter Blackwell. This is part of the Second Generation Transformer Engine. Blackwell’s tensor cores have doubled throughput for FP4, while FP8 and other formats like INT8 stay the same throughput. Don't listen to the marketing BS. They're using FP math for [AI TOPS](https://blogs.nvidia.com/blog/ai-decoded-tops/).\n\n# Flip Metering\n\nThe display engine has been updated with flip metering logic that allows for much more consistent frame pacing for Multiple Frame Generation and Frame Generation on 50 series.\n\n# Redesigned RT cores\n\nThe ray triangle intersection rate is doubled yet again to 8x per RT core as it’s been done with every generation since Turing. Here’s the ray triangle intersection rate for each generation per SM at iso-clocks:\n\n1. Turing = 1x\n2. Ampere = 2x\n3. Ada Lovelace = 4x\n4. Blackwell = 8x\n\nLike the previous generations two generations no changes for BVH traversal and ray box intersections have been disclosed.\n\nThe new SER implementation also seem to benefit ray tracing as per [RTX ](https://developer.nvidia.com/rtx-kit#iq771z)[Kit site](https://developer.nvidia.com/rtx-kit#iq771z):\n\n”*SER allows applications to easily reorder threads on the GPU, reducing the divergence effects that occur in particularly challenging ray tracing workloads like path tracing. New SER innovations in GeForce RTX 50 Series GPUs further improve efficiency and precision of shader reordering operations compared to GeForce RTX 40 Series GPUs.”*\n\n**\\*!?** Like Ada Lovelace’s SER it’s likely that the additional functionality requires integration in games, but it’s possible these advances are simply low level hardware optimizations. **\\*!?**\n\nRT cores are getting enhanced compression designed to reduce memory footprint.  \n\\- **\\*!?** Whether this also boosts performance and bandwidth or simply implies smaller BVH storage cost in VRAM remains to be seen. If it’s SRAM compression then this could be “sparsity for RT” (the analogy is high level, don’t take it too seriously), but technology behind remains undisclosed. **\\*!?**\n\nAll these changes to the RT core compound, which is why NVIDIA made this statement:\n\n”*This allows Blackwell GPUs to ray trace levels of geometry that were never before possible.”*\n\nThis also aligns with NVIDIA’s statements about the new RT cores being made for RTX mega geometry (see [RTX 5090 product page](https://www.nvidia.com/en-us/geforce/graphics-cards/50-series/rtx-5090/)), but what this actually means remains to be seen.  \n\\- **\\*!?** But we can infer reasonable conclusions based on the Ada Lovelace Whitepaper:\n\n”*When we ray trace complex environments, tracing costs increase slowly, a one-hundred-fold increase in geometry might only double tracing time. However, creating the data structure (BVH) that makes that small increase in time possible requires roughly linear time and memory; 100x more geometry could mean 100x more BVH build time, and 100x more memory.”*\n\nThe [RTX Mega Geometry SDK](https://www.youtube.com/watch?v=5PHBXY0FI5o&amp;t=110s) takes care of reducing the BVH build time and memory costs which allows for up to 100x more geometric detail and support for infinitely complex animated characters. But we still need much higher ray intersections and effective throughput (coherency management) and all the aforementioned advances in the RT core logic should accomplish that. With additional geometric complexity in future games the performance gap between generations should widen further. **\\*!?**\n\n# The Hardware Behind MFG and DLSS Transformer Models\n\nWith Ampere NVIDIA introduced support for fine-grained structured sparsity, a feature that allows for pruning of trained weights in the neural network. This compression enables up to a 2X increase in effective memory bandwidth and storage and up to 2X higher math throughput.\n\n**\\*!?** For new MFG, FG and the Ray Reconstruction, Upscaling and DLAA transformer enhanced models it’s possible they’re built from the ground up to utilize most if not all the architectural benefits of the Blackwell Architecture: fine-grained structural sparsity and FP4, FP6, FP8 support (Second Gen Transformer Engine). It's also possible it's an INT8 implementation like the DLSS CNNs (most likely), which will result in zero gains on a per SM basis vs Ampere and Ada at the same frequency.\n\nIt’s unknown if DLSS transformer models can benefit from sparsity, and it’ll depend on the nature of implementation, but given heavy use of self-attention in transformer models it's possible. The DLSS CNN models use of the sparsity feature remains undisclosed, but it's unlikely given how CNNs work. **\\*!?**\n\nNVIDIA said the new DLSS 4 transformer models for ray reconstruction and upscaling has [2x more parameters and requires 4x more compute](https://nvidianews.nvidia.com/news/nvidia-blackwell-geforce-rtx-50-series-opens-new-world-of-ai-computer-graphics).  \n\\- **\\*!?** Real world ms overhead vs the DNN model is unknown but don’t expect a miracle; the ms overhead will be significantly higher than the DNN version. This is a performance vs visuals trade-off.\n\nHere’s the FP16/INT8 tensor math throughput per SM for each generation at iso-clocks:\n\n1. Turing: 1x\n2. Ampere: 1x (2x with sparsity)\n3. Ada Lovelace: 1x (2x with fine grained structured sparsity), 2x FP8 (not supported previously)\n4. Blackwell: 1x (2x with fine grained structured sparsity), 4x FP4 (not supported previously)\n\nAnd as you can see the delta in theoretical FP16/INT8 will worsen model ms overhead with each every generation further back even if it's using INT8. If the new DLSS transformer models use FP(4-8) tensor math (Transformer Engine) and sparsity it'll only compound the model ms overhead and add additional VRAM storage cost with every generation further back. Remember that this is only relative as we still don’t know the exact overhead and storage cost for the new DLSS transformer models. **\\*!?**\n\n# Blackwell CUDA Cores\n\nDuring [the keynote](https://www.youtube.com/watch?v=uDup7cYNU6c&amp;t=498s) it was revealed the Ada Lovelace and Blackwell SMs are different. This is based on the limited information given during the keynote by Jensen:\n\n*\"...there is actually a concurent shader teraflops as well as an integer unit of equal performance so two dual shaders one is for floating point and the other is for integer.\"*\n\nIn addition [NVIDIA's website](https://www.nvidia.com/en-us/geforce/news/rtx-50-series-graphics-cards-gpu-laptop-announcements/) mention the following:\n\n*\"The Blackwell streaming multiprocessor (SM) has been updated with more processing throughput\"*\n\n**\\*!?** What this means and how much it differs from Turing and Ampere/Ada Lovelace is impossible to say with 100% certainty without the Blackwell 2.0 Whitepaper but I can speculate. We don’t know if it is a beefed up version of the dual issue pipeline from RDNA 3 (unlikely) or if the datapaths and logic for each FP and INT unit is Turing doubled (99% sure it's this one). Turing doubled is most likely as RDNA 3 doesn’t advertise dual issue as doubled cores per CU. If it’s an RDNA 3 like implementation and NVIDIA still advertises the cores then it is as bad as the Bulldozer marketing blunder. It only had 4 true cores but advertised them as 8.\n\nHere’s the two options for Blackwell compared on a SM level against Ada Lovelace, Ampere, Turing and Pascal:\n\n1. Blackwell dual issue cores: 64 FP32x2 + 64 INT32x2\n2. Blackwell true cores (Turing doubled): 128 FP32 + 128 INT32\n3. Ada Lovelace/Ampere: 64 FP32/INT32 + 64 FP32\n4. Turing: 64 FP32 + 64 INT32\n5. Pascal: 128 FP32/INT32\n\nMany people seem baffled by how NVIDIA managed more performance (Far Cry 6 4K Max RT) per SM with 50 series despite the sometimes lower clocks (5070 TI and 5090 has clock regression) vs 40 series. Well bigger SM math pipelines do explain a lot as this allows for larger increase in per SM throughput vs Ada lovelace.\n\nThe more integer heavy the game is the bigger the theoretical uplift (not real life!) should be with a Turing doubled SM. Compared to Ada Lovelace a 1/1 FP/INT math ratio workload receives a 100% speedup, whereas a 100% FP workload receives no speedup. It'll be interesting to see how much NVIDIA has increased maximum concurrent FP32+INT32 math throughput, but doubt it's anywhere near 2X over Ada Lovelace. With that said more integer heavy games should receive larger speedups up to a certain point, where the shaders can't be fed more data. Since a lot of AI inference (excluding LLMs) runs using integer math I'm 99.9% certain this increased integer capability was added to accelerate neural shading like Neural Texture Compression and Neural Materials + games in general. **\\*!?**\n\n# Media and Display Engine Changes\n\nDisplay:\n\n”*Blackwell has also been enhanced with PCIe Gen5 and DisplayPort 2.1b UHBR20, driving displays up to 8K 165Hz.”*\n\nMedia engine encoder and decoderhas been [upgraded](https://videocardz.com/newz/nvidia-geforce-rtx-50-series-adds-support-for-422-color-format-video-decoding-and-encoding):\n\n”*The RTX 50 chips support the 4:2:2 color format often used by professional videographers and include new support for multiview-HEVC for 3D and virtual reality (VR) video and a new AV1 Ultra High-Quality Mode.”*\n\nHardware support for 4:2:2 is new and the 5090 can decode up to 8x 4K 60 FPS streams per decoder.\n\n5% better quality with HEVC and AV1 encoding + 2x speed for H.264 video decoding.\n\n# Improved Power Management\n\n”*For GeForce RTX 50 Series laptops, new Max-Q technologies such as Advanced Power Gating, Low Latency Sleep, and Accelerated Frequency Switching increases battery life by up to 40%, compared to the previous generation.”*\n\n”*Advanced Power Gating technologies greatly reduce power by rapidly toggling unused parts of the GPU.*\n\n*Blackwell has significantly faster low power states. Low Latency Sleep allows the GPU to go to sleep more often, saving power even when the GPU is being used. This reduces power for gaming, Small Language Models (SLMs), and other creator and AI workloads on battery.*\n\n*Accelerated Frequency Switching boosts performance by adaptively optimizing clocks to each unique workload at microsecond level speeds.*\n\n*Voltage Optimized GDDR7 tunes graphics memory for optimal power efficiency with ultra low voltage states, delivering a massive jump in performance compared to last-generation’s GDDR6 VRAM.”*\n\nLaptop will benefit more from these changes, but the desktop should still see some benefits. These will probably mostly from Advanced Power Gating and Low Latency Sleep, but it’s possible they could also benefit from Accelerated Frequency Switching.\n\n# GDDR7\n\nBlackwell uses GDDR7 28-30gbps which lowers power draw vs GDDR6X (21-23gbps) and GDDR6 (17-18gbps + 20gbps (4070 G6)). The higher data rate also slashes memory latencies.\n\n# Blackwell’s Huge Leap in Compute Capability\n\nThe ballooned compute capability of Blackwell 2.0 or 50 series at launch remains an enigma. In one generation it has jumped by 2.9, whereas from Pascal to Ada Lovelace it increased by 2.8 in three generations.  \n\\- **\\*!?** Whether this supports Jensen’s assertion of Blackwell consumer being the biggest architectural redesign since 1999 when NVIDIA introduced the GeForce 256, the world’s first GPU, remains to be seen. The increased compute capability number could have something to do with neural shaders and tighter Tensor and CUDA core co-integration + other undisclosed changes. But it’s too early to say where the culprits lie. **\\*!?**\n\nFor reference here’s the official compute capabilities of the different architectures going all the way back to CUDA’s inception with Tesla in 2006:\n\nBlackwell: 12.8\n\nEnterprise – Blackwell: 10.0\n\nEnterprise - Hopper: 9.0\n\nAda Lovelace: 8.9\n\nAmpere: 8.6\n\nEnterprise – Ampere: 8.0\n\nTuring: 7.5\n\nEnterprise – Volta: 7.0\n\nPascal: 6.1\n\nEnterprise - Pascal 6.0\n\nMaxwell 2.0: 5.2\n\nMaxwell: 5\n\nBig Kepler: 3.5\n\nKepler: 3.0\n\nSmall Fermi: 2.1\n\nFermi: 2.0\n\nTesla: 1.0 + 1.3",
          "is_video": false,
          "awards": 0
        }
      },
      {
        "url": "https://www.pwc.com/us/en/tech-effect/ai-analytics/ai-predictions.html",
        "title": "2025 AI Business Predictions",
        "type": "article",
        "date": "2025-09-22T04:25:05.036Z",
        "score": 11,
        "metadata": {
          "snippet": "Beyond 2025: Costs will drop to near zero. Over time, new sources of computational power and new, renewable energy supplies will come online — dramatically ...",
          "domain": "www.pwc.com",
          "breadcrumb": "https://www.pwc.com › tech-effect › ai-analytics › ai-pr...",
          "is_featured": false,
          "content": "“AI adoption is progressing at a rapid clip, across PwC and in clients in every sector. 2025 will bring significant advancements in quality, accuracy, capability and automation that will continue to compound on each other, accelerating toward a period of exponential growth.” Matt Wood PwC US and Global Commercial Technology &amp; Innovation Officer"
        }
      }
    ]
  },
  "summary": "This analysis synthesizes 12 sources to provide actionable intelligence on AI ROI and implementation realities.\n\n**Key Findings:**\n• 40%: cost reduction in operations and a 25% increase in productivity within 18–24 months of implementatio\n• 60%: of total project costs, with senior AI engineers commanding $150,000-$200,000 annually in 2025\n• 20%: of initial project costs for scalability features, ensuring long-term value and system adaptability\n\n**Bottom Line:** The landscape shows both significant risks and opportunities. Success depends on avoiding common pitfalls while following proven implementation patterns.",
  "sections": [
    {
      "heading": "Executive Overview",
      "level": 1,
      "content": "This comprehensive analysis of enterprise AI implementation costs reality 2025 synthesizes findings from 16 data points across 12 sources. The research reveals critical insights for general decision-makers."
    },
    {
      "heading": "Critical Findings",
      "level": 1,
      "content": "Analysis reveals 0 risk factors and 0 opportunities. Despite challenges, clear paths to success emerge from the data.",
      "evidence": [
        {
          "claim": "40%",
          "sources": [
            "extracted"
          ],
          "confidence": 0.7
        },
        {
          "claim": "60%",
          "sources": [
            "extracted"
          ],
          "confidence": 0.7
        },
        {
          "claim": "20%",
          "sources": [
            "extracted"
          ],
          "confidence": 0.7
        },
        {
          "claim": "30%",
          "sources": [
            "extracted"
          ],
          "confidence": 0.7
        },
        {
          "claim": "25%",
          "sources": [
            "extracted"
          ],
          "confidence": 0.7
        }
      ]
    },
    {
      "heading": "Cost Reality Check",
      "level": 1,
      "content": "Implementation costs vary dramatically across organizations. Analysis of 10 cost data points reveals significant discrepancies between vendor claims and actual expenditures."
    },
    {
      "heading": "Success Patterns",
      "level": 1,
      "content": "Organizations achieving positive ROI share common characteristics: starting with simple use cases, measuring specific metrics, and scaling gradually. These patterns appear consistently across 9 success stories."
    },
    {
      "heading": "Strategic Recommendations",
      "level": 1,
      "content": "Based on the analysis of current market conditions: 1. **Move strategically**: Clear opportunities exist for early movers 2. **Focus on proven patterns**: Replicate successful approaches 3. **Scale gradually**: Build on early wins to expand 4. **Budget realistically**: Plan for costs 5-10x vendor estimates 5. **Build internal expertise**: Reduce dependency on external vendors"
    }
  ],
  "citations": [
    {
      "id": "cite_1",
      "text": "Custom AI Solutions Cost Guide 2025: Pricing Insights ...",
      "url": "https://medium.com/@dejanmarkovic_53716/custom-ai-solutions-cost-guide-2025-pricing-insights-revealed-cf19442261ec",
      "source": "article"
    },
    {
      "id": "cite_2",
      "text": "AI in the workplace: A report for 2025",
      "url": "https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/superagency-in-the-workplace-empowering-people-to-unlock-ais-full-potential-at-work",
      "source": "article"
    },
    {
      "id": "cite_3",
      "text": "AI Pricing: What's the True AI Cost for Businesses in 2025?",
      "url": "https://zylo.com/blog/ai-cost/",
      "source": "article"
    },
    {
      "id": "cite_4",
      "text": "The State Of AI Costs In 2025",
      "url": "https://www.cloudzero.com/state-of-ai-costs/",
      "source": "article"
    },
    {
      "id": "cite_5",
      "text": "ChatGPT 5: From Death Star to Easy-Bake Oven",
      "url": "https://www.baytechconsulting.com/blog/chatgpt-5-over-hyped-ai-2025",
      "source": "article"
    },
    {
      "id": "cite_6",
      "text": "Enterprise AI trends in 2025: what's real vs. pure hype",
      "url": "https://blog.superhuman.com/enterprise-ai-trends/",
      "source": "article"
    },
    {
      "id": "cite_7",
      "text": "MIT report: 95% of generative AI pilots at companies are ...",
      "url": "https://fortune.com/2025/08/18/mit-report-95-percent-generative-ai-pilots-at-companies-failing-cfo/",
      "source": "article"
    },
    {
      "id": "cite_8",
      "text": "The State of Enterprise AI in 2025: Measured Progress ...",
      "url": "https://weaviate.io/blog/enterprise-ai-trends-2025",
      "source": "article"
    },
    {
      "id": "cite_9",
      "text": "Could the upcoming AI crash be the crash that wipes out all the SHF's capital?",
      "url": "https://reddit.com/r/Superstonk/comments/1l5eaz9/could_the_upcoming_ai_crash_be_the_crash_that/",
      "source": "reddit"
    },
    {
      "id": "cite_10",
      "text": "NVDA is Worth $1000+ This Year - AI Will Be The Largest Wealth Transfer In The History of The World - Sam Altman Wasn't Joking...",
      "url": "https://reddit.com/r/wallstreetbets/comments/1aqf0zb/nvda_is_worth_1000_this_year_ai_will_be_the/",
      "source": "reddit"
    },
    {
      "id": "cite_12",
      "text": "Every Architectural Change For RTX 50 Series Disclosed So Far",
      "url": "https://reddit.com/r/hardware/comments/1hy3q7k/every_architectural_change_for_rtx_50_series/",
      "source": "reddit"
    },
    {
      "id": "cite_16",
      "text": "2025 AI Business Predictions",
      "url": "https://www.pwc.com/us/en/tech-effect/ai-analytics/ai-predictions.html",
      "source": "article"
    }
  ],
  "insights": [
    {
      "type": "trend",
      "title": "40%",
      "description": "cost reduction in operations and a 25% increase in productivity within 18–24 months of implementatio",
      "supporting": [
        "extracted"
      ]
    },
    {
      "type": "trend",
      "title": "60%",
      "description": "of total project costs, with senior AI engineers commanding $150,000-$200,000 annually in 2025",
      "supporting": [
        "extracted"
      ]
    },
    {
      "type": "trend",
      "title": "20%",
      "description": "of initial project costs for scalability features, ensuring long-term value and system adaptability",
      "supporting": [
        "extracted"
      ]
    },
    {
      "type": "trend",
      "title": "30%",
      "description": "higher implementation costs due to compliance requirements and specialized features",
      "supporting": [
        "extracted"
      ]
    },
    {
      "type": "trend",
      "title": "25%",
      "description": "of initial development costs, ensuring optimal performance and security",
      "supporting": [
        "extracted"
      ]
    },
    {
      "type": "trend",
      "title": "35%",
      "description": "to base costs, varying significantly based on existing infrastructure complexity",
      "supporting": [
        "extracted"
      ]
    },
    {
      "type": "trend",
      "title": "30%",
      "description": "while allowing for strategic scaling based on performance metrics",
      "supporting": [
        "extracted"
      ]
    },
    {
      "type": "trend",
      "title": "25%",
      "description": "of total project costs, as high-quality, properly structured data forms the foundation of any effect",
      "supporting": [
        "extracted"
      ]
    },
    {
      "type": "trend",
      "title": "30%",
      "description": "of expenses, varying based on the complexity of the business problem being addressed",
      "supporting": [
        "extracted"
      ]
    },
    {
      "type": "trend",
      "title": "20%",
      "description": "to the overall investment",
      "supporting": [
        "extracted"
      ]
    }
  ]
}